// https://github.com/grafana/agent-configurator

logging {
	level  = "warn"
	format = "logfmt"
}

tracing {
	sampling_fraction = 0.8
	write_to          = [otelcol.processor.batch.containers.input]
}

module.file "docker_compose" {
	filename = env("AGENT_CONFIG_FOLDER") + "/modules/docker_compose.river"

	arguments {
		metrics_endpoint = "http://gateway:8080"
		traces_endpoint  = "gateway:4317"
	}
}

discovery.docker "containers" {
	host = "unix:///var/run/docker.sock"

	filter {
		name   = "status"
		values = ["running"]
	}
}

discovery.relabel "containers" {
	targets = discovery.docker.containers.targets

	// filter by service name
	rule {
		source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
		action        = "keep"
		regex         = "(agent|mimir|grafana|loki|loki-.*|tempo|pyroscope)"
	}

	rule {
		source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
		regex         = "(.*)"
		replacement   = "monitoring-system/$1"
		target_label  = "job"
	}

	rule {
		source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
		regex         = "(.*)"
		target_label  = "pod"
	}

	rule {
		source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
		regex         = "(.*)"
		target_label  = "service_name"
	}

	rule {
		source_labels = ["__meta_docker_container_name"]
		regex         = "/(.*)"
		target_label  = "container"
	}
}

/********************************************
 * Metrics
 ********************************************/

prometheus.exporter.unix "containers" {
	set_collectors     = ["cpu"]
	disable_collectors = ["diskstats", "mdadm", "textfile", "hwmon"]
}

prometheus.scrape "integrations" {
	targets = concat(
		prometheus.exporter.unix.containers.targets,
	)
	scrape_interval = "15s"

	enable_protobuf_negotiation = true
	scrape_classic_histograms   = true

	clustering {
		enabled = true
	}

	forward_to = [prometheus.relabel.integrations.receiver]
}

prometheus.scrape "containers" {
	targets         = discovery.relabel.containers.output
	scrape_interval = "15s"

	enable_protobuf_negotiation = true
	scrape_classic_histograms   = true

	clustering {
		enabled = true
	}

	forward_to = [module.file.docker_compose.exports.metrics_receiver]
}

prometheus.scrape "minio" {
	targets = [{"__address__" = "minio:9000", "job" = "minio-job"}]

	scrape_interval = "15s"

	enable_protobuf_negotiation = true
	scrape_classic_histograms   = true

	clustering {
		enabled = true
	}
	metrics_path = "/minio/v2/metrics/cluster"

	forward_to = [prometheus.relabel.integrations.receiver]
}

prometheus.relabel "integrations" {
	rule {
		source_labels = ["job"]
		regex         = "(integrations|monitoring-system)/(.*)"
		target_label  = "pod"
		replacement   = "${2}"
	}

	rule {
		source_labels = ["job"]
		regex         = "(integrations|monitoring-system)/(.*)"
		target_label  = "container"
		replacement   = "${2}"
	}

	forward_to = [module.file.docker_compose.exports.metrics_receiver]
}

/********************************************
 * Jaeger for Traces Metrics
 ********************************************/

otelcol.receiver.jaeger "containers" {
	protocols {
		grpc {
			endpoint = "0.0.0.0:14250"
		}

		thrift_http {
			endpoint = "0.0.0.0:14268"
		}

		thrift_binary {
			endpoint = "0.0.0.0:6832"
		}

		thrift_compact {
			endpoint = "0.0.0.0:6831"
		}
	}

	output {
		metrics = [otelcol.processor.batch.containers.input]
		logs    = [otelcol.processor.batch.containers.input]
		traces  = [otelcol.processor.batch.containers.input]
	}
}

/********************************************
 * Otelcol for Traces Metrics
 ********************************************/

otelcol.receiver.otlp "containers" {
	grpc {
		endpoint = "0.0.0.0:4317"
	}

	http {
		endpoint = "0.0.0.0:4318"
	}

	output {
		metrics = [otelcol.processor.batch.containers.input]
		logs    = [otelcol.processor.batch.containers.input]
		traces  = [otelcol.processor.batch.containers.input]
	}
}

otelcol.processor.batch "containers" {
	output {
		metrics = [otelcol.processor.memory_limiter.containers.input]
		logs    = [otelcol.processor.memory_limiter.containers.input]
		traces  = [otelcol.processor.memory_limiter.containers.input]
	}
}

otelcol.processor.memory_limiter "containers" {
	check_interval = "1s"

	// limit = "150MiB" // alternatively, set `limit_percentage` and `spike_limit_percentage`
	limit_percentage       = 50
	spike_limit_percentage = 30

	output {
		metrics = [otelcol.processor.resourcedetection.containers.input]
		logs    = [otelcol.processor.resourcedetection.containers.input]
		traces  = [otelcol.processor.resourcedetection.containers.input]
	}
}

otelcol.processor.resourcedetection "containers" {
	// If you set up a OTEL_RESOURCE_ATTRIBUTES environment variable with value of TestKey=TestValue
	// then all logs, metrics, and traces have a resource attribute with a key TestKey and value of TestValue.
	detectors = ["env"]

	output {
		metrics = [otelcol.exporter.prometheus.containers.input]
		logs    = [otelcol.exporter.loki.containers.input]
		traces  = [module.file.docker_compose.exports.traces_receiver]
	}
}

otelcol.exporter.prometheus "containers" {
	forward_to = [module.file.docker_compose.exports.metrics_receiver]
}

otelcol.exporter.loki "containers" {
	forward_to = [loki.process.containers.receiver]
}

loki.process "containers" {
	stage.drop {
		longer_than = "8KB"
		older_than  = "12h"
	}

	stage.tenant {
		value = "fake"
	}

	forward_to = [module.file.docker_compose.exports.logs_receiver]
}
