/*
Module(metrics): Docker Containers Auto-Scraping
Description: Scrapes targets for metrics based on Docker Containers labels

Note: Every argument except for "forward_to" is optional, and does have a defined default value.  However, the values for these
      arguments are not defined using the default = " ... " argument syntax, but rather using the coalesce(argument.value, " ... ").
      This is because if the argument passed in from another consuming module is set to null, the default = " ... " syntax will
      does not override the value passed in, where coalesce() will return the first non-null value.


Following labels are available:

  metrics.agent.grafana.com/scrape: true

the default scraping scheme is http, only support http now.

  metrics.agent.grafana.com/scheme: http
or
  prometheus.io/scheme: http

the default path to scrape is /metrics, this can be specified as a single value which would override, the scrape path being used
for all ports attached to the target:

  metrics.agent.grafana.com/path: /metrics/some_path

the default port to scrape is the target port, this can be specified as a single value which would override the scrape port being
used for all ports attached to the target, note that even if an target had multiple targets, the relabel_config targets are
deduped before scraping:

  metrics.agent.grafana.com/port: 8080
or
  prometheus.io/port: 8080

the default interval to scrape is 15s, this can be specified as a single value which would override, the scrape interval being used
for all ports attached to the target:

  metrics.agent.grafana.com/interval: 15s
or
  prometheus.io/interval: 15s


the default timeout for scraping is 10s, this can be specified as a single value which would override, the scrape interval being
used for all ports attached to the target:

  metrics.agent.grafana.com/timeout: 10s
or
  prometheus.io/timeout: 10s

the default job is namespace/{{ service name }}  there may be a different job name is required because of a set of dashboards, rules,
etc. to support this there is a job annotation which will override the default value:

  metrics.agent.grafana.com/job: integrations/kubernetes/kube-state-metrics
or
  prometheus.io/job: integrations/kubernetes/kube-state-metrics
*/
argument "forward_to" {
	comment = "Must be a list(MetricsReceiver) where collected logs should be forwarded to"
}

argument "cluster" {
	optional = true
}

argument "namespace" {
	optional = true
}

argument "tenant" {
	comment  = "The tenant to write metrics to.  This does not have to be the tenantId, this is the value to look for in the logs.agent.grafana.com/tenant label, and this can be a regex. (default: (.*))"
	optional = true
}

argument "keep_metrics" {
	comment  = "A regex of metrics to keep (default: (.+))"
	optional = true
}

argument "drop_metrics" {
	comment  = "A regex of metrics to drop (default: \"\")"
	optional = true
}

argument "scrape_interval" {
	comment  = "How often to scrape metrics from the targets (default: 15s)"
	optional = true
}

argument "scrape_timeout" {
	comment  = "How long before a scrape times out (default: 10s)"
	optional = true
}

argument "clustering" {
	// Docs: https://grafana.com/docs/agent/latest/flow/concepts/clustering/
	comment  = "Whether or not clustering should be enabled (default: false)"
	optional = true
}

// get the available containers.
discovery.docker "dd_metrics" {
	host             = "unix:///var/run/docker.sock"
	refresh_interval = "15s"

	filter {
		name   = "status"
		values = ["running"]
	}
}

discovery.relabel "dr_docker_metrics" {
	targets = discovery.docker.dd_metrics.targets

	/****************************************************************************************************************
	* Handle Discovers From Docker Engine Containers Targets to Keep or Drop
	* https://grafana.com/docs/agent/latest/flow/reference/components/discovery.docker/#exported-fields
	****************************************************************************************************************/
	// allow resources to declare their metrics scraped or not
	// Example Annotation:
	//   metrics.agent.grafana.com/scrape: false
	//
	// the label prometheus.io/service-monitor: "false" is a common label for headless services, when performing endpoint
	// service discovery, if there is both a load-balanced service and headless service, this can result in duplicate
	// scrapes if the name of the service is attached as a label.  any targets with this label or annotation set should be dropped
	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_metrics_agent_grafana_com_scrape",
			"__meta_docker_container_label_prometheus_io_scrape",
		]
		separator    = ";"
		regex        = "^(?:;*)?(true|false).*$"
		replacement  = "$1"
		target_label = "__tmp_scrape"
	}

	// drop any targets that have scrape: false
	rule {
		action        = "drop"
		source_labels = ["__tmp_scrape"]
		regex         = "false"
	}

	// allow resources to declare the protocol to use when collecting metrics, the default value is "http",
	// Example Annotation:
	//   metrics.agent.grafana.com/scheme: http
	rule {
		action       = "replace"
		replacement  = "http"
		target_label = "__scheme__"
	}

	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_metrics_agent_grafana_com_scheme",
			"__meta_docker_container_label_prometheus_io_scheme",
		]
		separator    = ";"
		regex        = "^(?:;*)?(https?).*$"
		replacement  = "$1"
		target_label = "__scheme__"
	}

	// allow resources to declare their metrics the tenant their metrics should be sent to,
	// Example Annotation:
	//   metrics.agent.grafana.com/tenant: primary
	//
	// Note: This does not necessarily have to be the actual tenantId, it can be a friendly name as well that is simply used
	//       to determine if the metrics should be gathered for the current tenant
	rule {
		action        = "keep"
		source_labels = [
			"__meta_docker_container_label_metrics_agent_grafana_com_tenant",
			"__meta_docker_container_label_prometheus_io_tenant",
		]
		regex = "^(" + coalesce(argument.tenant.value, ".*") + ")$"
	}

	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_metrics_agent_grafana_com_port",
			"__meta_docker_container_label_prometheus_io_port",
		]
		separator    = ";"
		regex        = "^(?:;*)?(\\d+).*$"
		replacement  = "$1"
		target_label = "__tmp_metrics_port"
	}

	// allow resources to declare the port to use when collecting metrics, the default value is the discovered port from
	// Example Annotation:
	//   metrics.agent.grafana.com/port: 9090
	rule {
		action        = "replace"
		source_labels = [
			"__address__",
			"__tmp_metrics_port",
		]
		separator    = ";"
		regex        = "^([^:]+)(?::\\d+)?;(\\d+)$"
		replacement  = "$1:$2"
		target_label = "__address__"
	}

	// allow resources to declare their the path to use when collecting their metrics, the default value is "/metrics",
	// Example Annotation:
	//   metrics.agent.grafana.com/path: /metrics/foo
	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_metrics_agent_grafana_com_path",
			"__meta_docker_container_label_prometheus_io_path",
		]
		separator    = ";"
		regex        = "^(?:;*)?([^;]+).*$"
		replacement  = "$1"
		target_label = "__metrics_path__"
	}

	// allow resources to declare how often their metrics should be collected, the default value is 15s,
	// the following duration formats are supported (s|m|ms|h|d):
	// Example Annotation:
	//   metrics.agent.grafana.com/interval: 15s
	rule {
		action       = "replace"
		replacement  = coalesce(argument.scrape_interval.value, "15s")
		target_label = "__scrape_interval__"
	}

	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_metrics_agent_grafana_com_interval",
			"__meta_docker_container_label_prometheus_io_interval",
		]
		separator    = ";"
		regex        = "^(?:;*)?(\\d+(s|m|ms|h|d)).*$"
		replacement  = "$1"
		target_label = "__scrape_interval__"
	}

	// allow resources to declare the timeout of the scrape request, the default value is 10s,
	// the following duration formats are supported (s|m|ms|h|d):
	// Example Annotation:
	//   metrics.agent.grafana.com/timeout: 10s
	rule {
		action       = "replace"
		replacement  = coalesce(argument.scrape_timeout.value, "10s")
		target_label = "__scrape_timeout__"
	}

	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_metrics_agent_grafana_com_interval",
			"__meta_docker_container_label_prometheus_io_interval",
		]
		separator    = ";"
		regex        = "^(?:;*)?(\\d+(s|m|ms|h|d)).*$"
		replacement  = "$1"
		target_label = "__scrape_timeout__"
	}

	/********************************************
	* Handle Setting Common Labels
	********************************************/

	// set the cluster label
	rule {
		action       = "replace"
		replacement  = coalesce(argument.cluster.value, "docker-compose")
		target_label = "cluster"
	}

	// set the namespace label
	rule {
		action       = "replace"
		replacement  = coalesce(argument.namespace.value, "monitoring-system")
		target_label = "namespace"
	}

	// set a default job label to be the namespace/service_name
	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_com_docker_compose_service",
		]
		regex        = "^(?:;*)?([^;]+).*$"
		replacement  = coalesce(argument.namespace.value, "monitoring-system") + "/$1"
		target_label = "job"
	}

	// allow resources to declare their the job label value to use when collecting their metrics, the default value is "",
	// Example Annotation:
	//   metrics.agent.grafana.com/job: integrations/kubernetes/cadvisor
	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_metrics_agent_grafana_com_job",
			"__meta_docker_container_label_prometheus_io_job",
		]
		separator    = ";"
		regex        = "^(?:;*)?([^;]+).*$"
		replacement  = "$1"
		target_label = "job"
	}

	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_com_docker_compose_service",
		]
		regex        = "^(?:;*)?([^;]+).*$"
		replacement  = "$1"
		target_label = "pod"
	}

	rule {
		source_labels = ["__meta_docker_container_name"]
		regex         = "/(.*)"
		target_label  = "container"
	}

	rule {
		action        = "replace"
		source_labels = [
			"__meta_docker_container_label_com_docker_compose_service",
			"__meta_docker_container_label_app",
		]
		regex        = "^(?:;*)?([^;]+).*$"
		replacement  = "$1"
		target_label = "app"
	}
}

// only keep http targets
discovery.relabel "dr_keep_http_targets" {
	targets = discovery.relabel.dr_docker_metrics.output

	rule {
		action        = "keep"
		source_labels = ["__scheme__"]
		regex         = "http"
	}
}

// scrape http only targtets
prometheus.scrape "pc_docker_metrics" {
	forward_to = [prometheus.relabel.pr_docker_metrics.receiver]

	job_name        = "label-metrics-http"
	targets         = discovery.relabel.dr_keep_http_targets.output
	scheme          = "http"
	scrape_interval = coalesce(argument.scrape_interval.value, "1m")
	scrape_timeout  = coalesce(argument.scrape_timeout.value, "10s")

	enable_protobuf_negotiation = true
	scrape_classic_histograms   = true

	clustering {
		enabled = coalesce(argument.clustering.value, false)
	}
}

// perform generic relabeling using keep_metrics and drop_metrics
prometheus.relabel "pr_docker_metrics" {
	forward_to = argument.forward_to.value

	// keep only metrics that match the keep_metrics regex
	rule {
		action        = "keep"
		source_labels = ["__name__"]
		regex         = coalesce(argument.keep_metrics.value, "(.+)")
	}

	// drop metrics that match the drop_metrics regex
	rule {
		action        = "drop"
		source_labels = ["__name__"]
		regex         = coalesce(argument.drop_metrics.value, "")
	}
}
