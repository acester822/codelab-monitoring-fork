apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed
  namespace: monitoring-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: minio-sa
  namespace: monitoring-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: rollout-operator
    app.kubernetes.io/version: v0.7.0
    helm.sh/chart: rollout-operator-0.8.0
  name: mimir-distributed-rollout-operator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: mimir-distributed-rollout-operator
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - list
  - get
  - watch
  - delete
- apiGroups:
  - apps
  resources:
  - statefulsets
  verbs:
  - list
  - get
  - watch
- apiGroups:
  - apps
  resources:
  - statefulsets/status
  verbs:
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: mimir-distributed-rollout-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: mimir-distributed-rollout-operator
subjects:
- kind: ServiceAccount
  name: mimir-distributed-rollout-operator
---
apiVersion: v1
data:
  alertmanager_fallback_config.yaml: |
    receivers:
        - name: default-receiver
    route:
        receiver: default-receiver
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: alertmanager
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-alertmanager-fallback-config
  namespace: monitoring-system
---
apiVersion: v1
data:
  mimir.yaml: |2

    activity_tracker:
      filepath: /active-query-tracker/activity.log
    alertmanager:
      data_dir: /data
      enable_api: true
      external_url: /alertmanager
      fallback_config_file: /configs/alertmanager_fallback_config.yaml
    alertmanager_storage:
      backend: s3
      s3:
        access_key_id: grafana-mimir
        bucket_name: mimir-ruler
        endpoint: mimir-distributed-minio.monitoring-system.svc:9000
        insecure: true
        secret_access_key: supersecret
    blocks_storage:
      backend: s3
      bucket_store:
        sync_dir: /data/tsdb-sync
      s3:
        access_key_id: grafana-mimir
        bucket_name: mimir-tsdb
        endpoint: mimir-distributed-minio.monitoring-system.svc:9000
        insecure: true
        secret_access_key: supersecret
      tsdb:
        dir: /data/tsdb
        head_compaction_interval: 15m
        wal_replay_concurrency: 3
    compactor:
      compaction_interval: 30m
      data_dir: /data
      deletion_delay: 2h
      first_level_compaction_wait_period: 25m
      max_closing_blocks_concurrency: 2
      max_opening_blocks_concurrency: 4
      sharding_ring:
        wait_stability_min_duration: 1m
      symbols_flushers_concurrency: 4
    frontend:
      parallelize_shardable_queries: true
      scheduler_address: mimir-distributed-query-scheduler-headless.monitoring-system.svc:9095
    frontend_worker:
      grpc_client_config:
        max_send_msg_size: 419430400
      scheduler_address: mimir-distributed-query-scheduler-headless.monitoring-system.svc:9095
    ingester:
      ring:
        final_sleep: 0s
        num_tokens: 512
        tokens_file_path: /data/tokens
        unregister_on_shutdown: false
        zone_awareness_enabled: true
    ingester_client:
      grpc_client_config:
        max_recv_msg_size: 104857600
        max_send_msg_size: 104857600
    limits:
      max_cache_freshness: 10m
      max_query_parallelism: 240
      max_total_query_length: 12000h
    memberlist:
      abort_if_cluster_join_fails: false
      compression_enabled: false
      join_members:
      - dns+mimir-distributed-gossip-ring.monitoring-system.svc.cluster.local:7946
    querier:
      max_concurrent: 16
    query_scheduler:
      max_outstanding_requests_per_tenant: 800
    ruler:
      alertmanager_url: dnssrvnoa+http://_http-metrics._tcp.mimir-distributed-alertmanager-headless.monitoring-system.svc.cluster.local/alertmanager
      enable_api: true
      rule_path: /data
    ruler_storage:
      backend: s3
      s3:
        access_key_id: grafana-mimir
        bucket_name: mimir-ruler
        endpoint: mimir-distributed-minio.monitoring-system.svc:9000
        insecure: true
        secret_access_key: supersecret
    runtime_config:
      file: /var/mimir/runtime.yaml
    server:
      grpc_server_max_concurrent_streams: 1000
      grpc_server_max_connection_age: 2m
      grpc_server_max_connection_age_grace: 5m
      grpc_server_max_connection_idle: 1m
    store_gateway:
      sharding_ring:
        kvstore:
          prefix: multi-zone/
        tokens_file_path: /data/tokens
        unregister_on_shutdown: false
        wait_stability_min_duration: 1m
        zone_awareness_enabled: true
    usage_stats:
      installation_mode: helm
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-config
  namespace: monitoring-system
---
apiVersion: v1
data:
  add-policy: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/tmp/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"

    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }

    # checkPolicyExists ($policy)
    # Check if the policy exists, by using the exit code of `mc admin policy info`
    checkPolicyExists() {
      POLICY=$1
      CMD=$(${MC} admin policy info myminio $POLICY > /dev/null 2>&1)
      return $?
    }

    # createPolicy($name, $filename)
    createPolicy () {
      NAME=$1
      FILENAME=$2

      # Create the name if it does not exist
      echo "Checking policy: $NAME (in /config/$FILENAME.json)"
      if ! checkPolicyExists $NAME ; then
        echo "Creating policy '$NAME'"
      else
        echo "Policy '$NAME' already exists."
      fi
      ${MC} admin policy add myminio $NAME /config/$FILENAME.json

    }

    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
  add-svcacct: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/tmp/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"

    # AccessKey and secretkey credentials file are added to prevent shell execution errors caused by special characters.
    # Special characters for example : ',",<,>,{,}
    MINIO_ACCESSKEY_SECRETKEY_TMP="/tmp/accessKey_and_secretKey_svcacct_tmp"

    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 2 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }

    # checkSvcacctExists ()
    # Check if the svcacct exists, by using the exit code of `mc admin user svcacct info`
    checkSvcacctExists() {
      CMD=$(${MC} admin user svcacct info myminio $(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP) > /dev/null 2>&1)
      return $?
    }

    # createSvcacct ($user)
    createSvcacct () {
      USER=$1
      FILENAME=$2
      #check accessKey_and_secretKey_tmp file
      if [[ ! -f $MINIO_ACCESSKEY_SECRETKEY_TMP ]];then
        echo "credentials file does not exist"
        return 1
      fi
      if [[ $(cat $MINIO_ACCESSKEY_SECRETKEY_TMP|wc -l) -ne 2 ]];then
        echo "credentials file is invalid"
        rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP
        return 1
      fi
      SVCACCT=$(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP)
      # Create the svcacct if it does not exist
      if ! checkSvcacctExists ; then
        echo "Creating svcacct '$SVCACCT'"
        # Check if policy file is define
        if [ -z $FILENAME ]; then
          ${MC} admin user svcacct add --access-key $(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP) --secret-key $(tail -n1 $MINIO_ACCESSKEY_SECRETKEY_TMP) myminio $USER
        else
          ${MC} admin user svcacct add --access-key $(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP) --secret-key $(tail -n1 $MINIO_ACCESSKEY_SECRETKEY_TMP) --policy /config/$FILENAME.json myminio $USER
        fi
      else
        echo "Svcacct '$SVCACCT' already exists."
      fi
      #clean up credentials files.
      rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP
    }

    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
  add-user: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/tmp/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"

    # AccessKey and secretkey credentials file are added to prevent shell execution errors caused by special characters.
    # Special characters for example : ',",<,>,{,}
    MINIO_ACCESSKEY_SECRETKEY_TMP="/tmp/accessKey_and_secretKey_tmp"

    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }

    # checkUserExists ()
    # Check if the user exists, by using the exit code of `mc admin user info`
    checkUserExists() {
      CMD=$(${MC} admin user info myminio $(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP) > /dev/null 2>&1)
      return $?
    }

    # createUser ($policy)
    createUser() {
      POLICY=$1
      #check accessKey_and_secretKey_tmp file
      if [[ ! -f $MINIO_ACCESSKEY_SECRETKEY_TMP ]];then
        echo "credentials file does not exist"
        return 1
      fi
      if [[ $(cat $MINIO_ACCESSKEY_SECRETKEY_TMP|wc -l) -ne 2 ]];then
        echo "credentials file is invalid"
        rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP
        return 1
      fi
      USER=$(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP)
      # Create the user if it does not exist
      if ! checkUserExists ; then
        echo "Creating user '$USER'"
        cat $MINIO_ACCESSKEY_SECRETKEY_TMP | ${MC} admin user add myminio
      else
        echo "User '$USER' already exists."
      fi
      #clean up credentials files.
      rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP

      # set policy for user
      if [ ! -z $POLICY -a $POLICY != " " ] ; then
          echo "Adding policy '$POLICY' for '$USER'"
          ${MC} admin policy set myminio $POLICY user=$USER
      else
          echo "User '$USER' has no policy attached."
      fi
    }

    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme



    # Create the users
    echo console > $MINIO_ACCESSKEY_SECRETKEY_TMP
    echo console123 >> $MINIO_ACCESSKEY_SECRETKEY_TMP
    createUser consoleAdmin
  custom-command: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/tmp/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"

    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }

    # runCommand ($@)
    # Run custom mc command
    runCommand() {
      ${MC} "$@"
      return $?
    }

    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
  initialize: "#!/bin/sh\nset -e ; # Have script exit in the event of a failed command.\nMC_CONFIG_DIR=\"/tmp/minio/mc/\"\nMC=\"/usr/bin/mc
    --insecure --config-dir ${MC_CONFIG_DIR}\"\n\n# connectToMinio\n# Use a check-sleep-check
    loop to wait for MinIO service to be available\nconnectToMinio() {\n  SCHEME=$1\n
    \ ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts\n  set -e ; # fail if we can't read
    the keys.\n  ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword)
    ;\n  set +e ; # The connections to minio are allowed to fail.\n  echo \"Connecting
    to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT\" ;\n  MC_COMMAND=\"${MC}
    alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET\" ;\n
    \ $MC_COMMAND ;\n  STATUS=$? ;\n  until [ $STATUS = 0 ]\n  do\n    ATTEMPTS=`expr
    $ATTEMPTS + 1` ;\n    echo \\\"Failed attempts: $ATTEMPTS\\\" ;\n    if [ $ATTEMPTS
    -gt $LIMIT ]; then\n      exit 1 ;\n    fi ;\n    sleep 2 ; # 1 second intervals
    between attempts\n    $MC_COMMAND ;\n    STATUS=$? ;\n  done ;\n  set -e ; # reset
    `e` as active\n  return 0\n}\n\n# checkBucketExists ($bucket)\n# Check if the
    bucket exists, by using the exit code of `mc ls`\ncheckBucketExists() {\n  BUCKET=$1\n
    \ CMD=$(${MC} stat myminio/$BUCKET > /dev/null 2>&1)\n  return $?\n}\n\n# createBucket
    ($bucket, $policy, $purge)\n# Ensure bucket exists, purging if asked to\ncreateBucket()
    {\n  BUCKET=$1\n  POLICY=$2\n  PURGE=$3\n  VERSIONING=$4\n  OBJECTLOCKING=$5\n\n
    \ # Purge the bucket, if set & exists\n  # Since PURGE is user input, check explicitly
    for `true`\n  if [ $PURGE = true ]; then\n    if checkBucketExists $BUCKET ; then\n
    \     echo \"Purging bucket '$BUCKET'.\"\n      set +e ; # don't exit if this
    fails\n      ${MC} rm -r --force myminio/$BUCKET\n      set -e ; # reset `e` as
    active\n    else\n      echo \"Bucket '$BUCKET' does not exist, skipping purge.\"\n
    \   fi\n  fi\n\n# Create the bucket if it does not exist and set objectlocking
    if enabled (NOTE: versioning will be not changed if OBJECTLOCKING is set because
    it enables versioning to the Buckets created)\nif ! checkBucketExists $BUCKET
    ; then\n    if [ ! -z $OBJECTLOCKING ] ; then\n      if [ $OBJECTLOCKING = true
    ] ; then\n          echo \"Creating bucket with OBJECTLOCKING '$BUCKET'\"\n          ${MC}
    mb --with-lock myminio/$BUCKET\n      elif [ $OBJECTLOCKING = false ] ; then\n
    \           echo \"Creating bucket '$BUCKET'\"\n            ${MC} mb myminio/$BUCKET\n
    \     fi\n  elif [ -z $OBJECTLOCKING ] ; then\n        echo \"Creating bucket
    '$BUCKET'\"\n        ${MC} mb myminio/$BUCKET\n  else\n    echo \"Bucket '$BUCKET'
    already exists.\"  \n  fi\n  fi\n\n\n  # set versioning for bucket if objectlocking
    is disabled or not set\n  if [ -z $OBJECTLOCKING ] ; then\n  if [ ! -z $VERSIONING
    ] ; then\n    if [ $VERSIONING = true ] ; then\n        echo \"Enabling versioning
    for '$BUCKET'\"\n        ${MC} version enable myminio/$BUCKET\n    elif [ $VERSIONING
    = false ] ; then\n        echo \"Suspending versioning for '$BUCKET'\"\n        ${MC}
    version suspend myminio/$BUCKET\n    fi\n    fi\n  else\n      echo \"Bucket '$BUCKET'
    versioning unchanged.\"\n  fi\n\n\n  # At this point, the bucket should exist,
    skip checking for existence\n  # Set policy on the bucket\n  echo \"Setting policy
    of bucket '$BUCKET' to '$POLICY'.\"\n  ${MC} anonymous set $POLICY myminio/$BUCKET\n}\n\n#
    Try connecting to MinIO instance\nscheme=http\nconnectToMinio $scheme\n\n\n\n#
    Create the buckets\ncreateBucket mimir-tsdb \"none\" false false false\ncreateBucket
    mimir-ruler \"none\" false false false\ncreateBucket enterprise-metrics-tsdb \"none\"
    false false false\ncreateBucket enterprise-metrics-admin \"none\" false false
    false\ncreateBucket enterprise-metrics-ruler \"none\" false false false"
kind: ConfigMap
metadata:
  labels:
    app: minio
    chart: minio-5.0.7
    heritage: Helm
    release: mimir-distributed
  name: mimir-distributed-minio
  namespace: monitoring-system
---
apiVersion: v1
data:
  nginx.conf: |
    worker_processes  5;  ## Default: 1
    error_log  /dev/stderr error;
    pid        /tmp/nginx.pid;
    worker_rlimit_nofile 8192;

    events {
      worker_connections  4096;  ## Default: 1024
    }

    http {
      client_body_temp_path /tmp/client_temp;
      proxy_temp_path       /tmp/proxy_temp_path;
      fastcgi_temp_path     /tmp/fastcgi_temp;
      uwsgi_temp_path       /tmp/uwsgi_temp;
      scgi_temp_path        /tmp/scgi_temp;

      default_type application/octet-stream;
      log_format   main '$remote_addr - $remote_user [$time_local]  $status '
            '"$request" $body_bytes_sent "$http_referer" '
            '"$http_user_agent" "$http_x_forwarded_for"';
      access_log   /dev/stderr  main;

      sendfile     on;
      tcp_nopush   on;
      resolver kube-dns.kube-system.svc.cluster.local;

      # Ensure that X-Scope-OrgID is always present, default to the no_auth_tenant for backwards compatibility when multi-tenancy was turned off.
      map $http_x_scope_orgid $ensured_x_scope_orgid {
        default $http_x_scope_orgid;
        "" "anonymous";
      }

      proxy_read_timeout 300;
      server {
        listen 8080;
        listen [::]:8080;

        location = / {
          return 200 'OK';
          auth_basic off;
        }

        proxy_set_header X-Scope-OrgID $ensured_x_scope_orgid;

        # Distributor endpoints
        location /distributor {
          set $distributor mimir-distributed-distributor-headless.monitoring-system.svc.cluster.local;
          proxy_pass      http://$distributor:8080$request_uri;
        }
        location = /api/v1/push {
          set $distributor mimir-distributed-distributor-headless.monitoring-system.svc.cluster.local;
          proxy_pass      http://$distributor:8080$request_uri;
        }
        location /otlp/v1/metrics {
          set $distributor mimir-distributed-distributor-headless.monitoring-system.svc.cluster.local;
          proxy_pass      http://$distributor:8080$request_uri;
        }

        # Alertmanager endpoints
        location /alertmanager {
          set $alertmanager mimir-distributed-alertmanager-headless.monitoring-system.svc.cluster.local;
          proxy_pass      http://$alertmanager:8080$request_uri;
        }
        location = /multitenant_alertmanager/status {
          set $alertmanager mimir-distributed-alertmanager-headless.monitoring-system.svc.cluster.local;
          proxy_pass      http://$alertmanager:8080$request_uri;
        }
        location = /api/v1/alerts {
          set $alertmanager mimir-distributed-alertmanager-headless.monitoring-system.svc.cluster.local;
          proxy_pass      http://$alertmanager:8080$request_uri;
        }

        # Ruler endpoints
        location /prometheus/config/v1/rules {
          set $ruler mimir-distributed-ruler.monitoring-system.svc.cluster.local;
          proxy_pass      http://$ruler:8080$request_uri;
        }
        location /prometheus/api/v1/rules {
          set $ruler mimir-distributed-ruler.monitoring-system.svc.cluster.local;
          proxy_pass      http://$ruler:8080$request_uri;
        }

        location /prometheus/api/v1/alerts {
          set $ruler mimir-distributed-ruler.monitoring-system.svc.cluster.local;
          proxy_pass      http://$ruler:8080$request_uri;
        }
        location = /ruler/ring {
          set $ruler mimir-distributed-ruler.monitoring-system.svc.cluster.local;
          proxy_pass      http://$ruler:8080$request_uri;
        }

        # Rest of /prometheus goes to the query frontend
        location /prometheus {
          set $query_frontend mimir-distributed-query-frontend.monitoring-system.svc.cluster.local;
          proxy_pass      http://$query_frontend:8080$request_uri;
        }

        # Buildinfo endpoint can go to any component
        location = /api/v1/status/buildinfo {
          set $query_frontend mimir-distributed-query-frontend.monitoring-system.svc.cluster.local;
          proxy_pass      http://$query_frontend:8080$request_uri;
        }

        # Compactor endpoint for uploading blocks
        location /api/v1/upload/block/ {
          set $compactor mimir-distributed-compactor.monitoring-system.svc.cluster.local;
          proxy_pass      http://$compactor:8080$request_uri;
        }
      }
    }
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: nginx
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-nginx
  namespace: monitoring-system
---
apiVersion: v1
data:
  runtime.yaml: |2

    {}
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-runtime
  namespace: monitoring-system
---
apiVersion: v1
data:
  rootPassword: c3VwZXJzZWNyZXQ=
  rootUser: Z3JhZmFuYS1taW1pcg==
kind: Secret
metadata:
  labels:
    app: minio
    chart: minio-5.0.7
    heritage: Helm
    release: mimir-distributed
  name: mimir-distributed-minio
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: alertmanager
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-alertmanager
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: alertmanager
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: alertmanager
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    prometheus.io/service-monitor: "false"
  name: mimir-distributed-alertmanager-headless
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  - name: cluster
    port: 9094
    protocol: TCP
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: alertmanager
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: compactor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-compactor
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: compactor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-distributor
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    prometheus.io/service-monitor: "false"
  name: mimir-distributed-distributor-headless
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: gossip-ring
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-gossip-ring
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - appProtocol: tcp
    name: gossip-ring
    port: 7946
    protocol: TCP
    targetPort: 7946
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    prometheus.io/service-monitor: "false"
  name: mimir-distributed-ingester-headless
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: ingester-zone-a
    rollout-group: ingester
    zone: zone-a
  name: mimir-distributed-ingester-zone-a
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
    rollout-group: ingester
    zone: zone-a
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: ingester-zone-b
    rollout-group: ingester
    zone: zone-b
  name: mimir-distributed-ingester-zone-b
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
    rollout-group: ingester
    zone: zone-b
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: ingester-zone-c
    rollout-group: ingester
    zone: zone-c
  name: mimir-distributed-ingester-zone-c
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
    rollout-group: ingester
    zone: zone-c
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: minio
    chart: minio-5.0.7
    heritage: Helm
    monitoring: "true"
    release: mimir-distributed
  name: mimir-distributed-minio
  namespace: monitoring-system
spec:
  ports:
  - name: http
    port: 9000
    protocol: TCP
    targetPort: 9000
  selector:
    app: minio
    release: mimir-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: minio
    chart: minio-5.0.7
    heritage: Helm
    release: mimir-distributed
  name: mimir-distributed-minio-console
  namespace: monitoring-system
spec:
  ports:
  - name: http
    port: 9001
    protocol: TCP
    targetPort: 9001
  selector:
    app: minio
    release: mimir-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: nginx
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-nginx
  namespace: monitoring-system
spec:
  ports:
  - name: http-metric
    port: 80
    protocol: TCP
    targetPort: http-metric
  selector:
    app.kubernetes.io/component: nginx
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: overrides-exporter
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-overrides-exporter
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: overrides-exporter
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: querier
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-querier
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: querier
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-query-frontend
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-query-scheduler
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    prometheus.io/service-monitor: "false"
  name: mimir-distributed-query-scheduler-headless
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ruler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-ruler
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  selector:
    app.kubernetes.io/component: ruler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    prometheus.io/service-monitor: "false"
  name: mimir-distributed-store-gateway-headless
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: store-gateway-zone-a
    rollout-group: store-gateway
    zone: zone-a
  name: mimir-distributed-store-gateway-zone-a
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
    rollout-group: store-gateway
    zone: zone-a
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: store-gateway-zone-b
    rollout-group: store-gateway
    zone: zone-b
  name: mimir-distributed-store-gateway-zone-b
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
    rollout-group: store-gateway
    zone: zone-b
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: store-gateway-zone-c
    rollout-group: store-gateway
    zone: zone-c
  name: mimir-distributed-store-gateway-zone-c
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
    protocol: TCP
    targetPort: http-metrics
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/name: mimir
    rollout-group: store-gateway
    zone: zone-c
  type: ClusterIP
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    app: minio
    chart: minio-5.0.7
    heritage: Helm
    release: mimir-distributed
  name: mimir-distributed-minio
  namespace: monitoring-system
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-distributor
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: distributor
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: distributor
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=distributor
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        env:
        - name: GOMAXPROCS
          value: "8"
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: distributor
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
          subPath: null
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 60
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: distributor
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: storage
      - emptyDir: {}
        name: active-queries
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: minio
    chart: minio-5.0.7
    heritage: Helm
    release: mimir-distributed
  name: mimir-distributed-minio
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
      release: mimir-distributed
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: d4175408592138d22df9b5b3fbaba3aa77e90602ab218fbd6de56e70359e367d
        checksum/secrets: d1df60d25843238e1e18a46f7117aab0a7d87f6324b4efe186c70b20efea9e01
      labels:
        app: minio
        release: mimir-distributed
      name: mimir-distributed-minio
    spec:
      containers:
      - command:
        - /bin/sh
        - -ce
        - /usr/bin/docker-entrypoint.sh minio server /export -S /etc/minio/certs/
          --address :9000 --console-address :9001
        env:
        - name: MINIO_ROOT_USER
          valueFrom:
            secretKeyRef:
              key: rootUser
              name: mimir-distributed-minio
        - name: MINIO_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              key: rootPassword
              name: mimir-distributed-minio
        - name: MINIO_PROMETHEUS_AUTH_TYPE
          value: public
        image: quay.io/minio/minio:RELEASE.2023-02-10T18-48-39Z
        imagePullPolicy: IfNotPresent
        name: minio
        ports:
        - containerPort: 9000
          name: http
        - containerPort: 9001
          name: http-console
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - mountPath: /tmp/credentials
          name: minio-user
          readOnly: true
        - mountPath: /export
          name: export
      securityContext:
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 1000
        runAsUser: 1000
      serviceAccountName: minio-sa
      volumes:
      - name: export
        persistentVolumeClaim:
          claimName: mimir-distributed-minio
      - name: minio-user
        secret:
          secretName: mimir-distributed-minio
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: nginx
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-nginx
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: nginx
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: a594a234f16bff2646bbee98e83acdc4f706ec512471708eed4ba14285ec9310
      labels:
        app.kubernetes.io/component: nginx
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
      namespace: monitoring-system
    spec:
      containers:
      - env: null
        envFrom: null
        image: docker.io/nginxinc/nginx-unprivileged:1.24-alpine
        imagePullPolicy: IfNotPresent
        name: nginx
        ports:
        - containerPort: 8080
          name: http-metric
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /
            port: http-metric
          initialDelaySeconds: 15
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/nginx
          name: config
        - mountPath: /tmp
          name: tmp
        - mountPath: /docker-entrypoint.d
          name: docker-entrypoint-d-override
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 30
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: nginx
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          name: mimir-distributed-nginx
        name: config
      - emptyDir: {}
        name: tmp
      - emptyDir: {}
        name: docker-entrypoint-d-override
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: overrides-exporter
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-overrides-exporter
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: overrides-exporter
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: overrides-exporter
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=overrides-exporter
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
        name: overrides-exporter
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
          subPath: null
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 60
      tolerations: []
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: storage
      - emptyDir: {}
        name: active-queries
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: querier
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-querier
  namespace: monitoring-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/component: querier
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: querier
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
    spec:
      affinity: {}
      containers:
      - args:
        - -target=querier
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        env:
        - name: GOMAXPROCS
          value: "5"
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: querier
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
          subPath: null
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 180
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: querier
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: storage
      - emptyDir: {}
        name: active-queries
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-query-frontend
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: query-frontend
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  strategy:
    rollingUpdate:
      maxSurge: 15%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: query-frontend
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=query-frontend
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: query-frontend
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /etc/mimir
          name: config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 180
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: query-frontend
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: storage
      - emptyDir: {}
        name: active-queries
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-query-scheduler
  namespace: monitoring-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/component: query-scheduler
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: query-scheduler
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
    spec:
      affinity: {}
      containers:
      - args:
        - -target=query-scheduler
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -server.grpc.keepalive.max-connection-age=2562047h
        - -server.grpc.keepalive.max-connection-age-grace=2562047h
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: query-scheduler
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /etc/mimir
          name: config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 180
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: query-scheduler
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: storage
      - emptyDir: {}
        name: active-queries
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: ruler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-ruler
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: ruler
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  strategy:
    rollingUpdate:
      maxSurge: 50%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: ruler
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=ruler
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: ruler
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
          subPath: null
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 180
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: ruler
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: storage
      - emptyDir: {}
        name: active-queries
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: rollout-operator
    app.kubernetes.io/version: v0.7.0
    helm.sh/chart: rollout-operator-0.8.0
  name: mimir-distributed-rollout-operator
spec:
  minReadySeconds: 10
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: rollout-operator
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/name: rollout-operator
    spec:
      containers:
      - args:
        - -kubernetes.namespace=monitoring-system
        image: grafana/rollout-operator:v0.7.0
        imagePullPolicy: IfNotPresent
        name: rollout-operator
        ports:
        - containerPort: 8001
          name: http-metrics
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 5
          timeoutSeconds: 1
        resources:
          limits:
            cpu: "1"
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed-rollout-operator
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: alertmanager
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-alertmanager
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: alertmanager
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  serviceName: mimir-distributed-alertmanager
  template:
    metadata:
      annotations:
        checksum/alertmanager-fallback-config: c7f2209230077ea5ce368bc5d999cd87b900c3672f6331a6bf3e5a15808c3910
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: alertmanager
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=alertmanager
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: alertmanager
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
        resources:
          requests:
            cpu: 10m
            memory: 32Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
        - mountPath: /configs/
          name: alertmanager-fallback-config
        - mountPath: /tmp
          name: tmp
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 60
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: alertmanager
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: tmp
      - emptyDir: {}
        name: active-queries
      - configMap:
          name: mimir-distributed-alertmanager-fallback-config
        name: alertmanager-fallback-config
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: compactor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-compactor
  namespace: monitoring-system
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: compactor
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
  serviceName: mimir-distributed-compactor
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: compactor
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=compactor
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: compactor
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 60
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 240
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: compactor
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: active-queries
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    rollout-max-unavailable: "50"
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: ingester-zone-a
    rollout-group: ingester
    zone: zone-a
  name: mimir-distributed-ingester-zone-a
  namespace: monitoring-system
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: ingester
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
      rollout-group: ingester
      zone: zone-a
  serviceName: mimir-distributed-ingester-headless
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: ingester
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
        name: ingester-zone-a
        rollout-group: ingester
        zone: zone-a
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=ingester
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -ingester.ring.instance-availability-zone=zone-a
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: ingester
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 60
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 240
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: ingester
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: active-queries
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    rollout-max-unavailable: "50"
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: ingester-zone-b
    rollout-group: ingester
    zone: zone-b
  name: mimir-distributed-ingester-zone-b
  namespace: monitoring-system
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: ingester
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
      rollout-group: ingester
      zone: zone-b
  serviceName: mimir-distributed-ingester-headless
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: ingester
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
        name: ingester-zone-b
        rollout-group: ingester
        zone: zone-b
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=ingester
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -ingester.ring.instance-availability-zone=zone-b
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: ingester
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 60
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 240
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: ingester
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: active-queries
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    rollout-max-unavailable: "50"
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: ingester-zone-c
    rollout-group: ingester
    zone: zone-c
  name: mimir-distributed-ingester-zone-c
  namespace: monitoring-system
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: ingester
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
      rollout-group: ingester
      zone: zone-c
  serviceName: mimir-distributed-ingester-headless
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: ingester
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
        name: ingester-zone-c
        rollout-group: ingester
        zone: zone-c
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=ingester
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -ingester.ring.instance-availability-zone=zone-c
        env: null
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: ingester
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 60
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 240
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: ingester
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: active-queries
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    rollout-max-unavailable: "50"
  labels:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: store-gateway-zone-a
    rollout-group: store-gateway
    zone: zone-a
  name: mimir-distributed-store-gateway-zone-a
  namespace: monitoring-system
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: store-gateway
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
      rollout-group: store-gateway
      zone: zone-a
  serviceName: mimir-distributed-store-gateway-headless
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: store-gateway
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
        name: store-gateway-zone-a
        rollout-group: store-gateway
        zone: zone-a
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=store-gateway
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -store-gateway.sharding-ring.instance-availability-zone=zone-a
        env:
        - name: GOMAXPROCS
          value: "5"
        - name: GOMEMLIMIT
          value: "536870912"
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: store-gateway
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 60
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 240
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: store-gateway
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: active-queries
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    rollout-max-unavailable: "50"
  labels:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: store-gateway-zone-b
    rollout-group: store-gateway
    zone: zone-b
  name: mimir-distributed-store-gateway-zone-b
  namespace: monitoring-system
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: store-gateway
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
      rollout-group: store-gateway
      zone: zone-b
  serviceName: mimir-distributed-store-gateway-headless
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: store-gateway
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
        name: store-gateway-zone-b
        rollout-group: store-gateway
        zone: zone-b
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=store-gateway
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -store-gateway.sharding-ring.instance-availability-zone=zone-b
        env:
        - name: GOMAXPROCS
          value: "5"
        - name: GOMEMLIMIT
          value: "536870912"
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: store-gateway
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 60
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 240
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: store-gateway
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: active-queries
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    rollout-max-unavailable: "50"
  labels:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
    name: store-gateway-zone-c
    rollout-group: store-gateway
    zone: zone-c
  name: mimir-distributed-store-gateway-zone-c
  namespace: monitoring-system
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: store-gateway
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
      rollout-group: store-gateway
      zone: zone-c
  serviceName: mimir-distributed-store-gateway-headless
  template:
    metadata:
      annotations:
        checksum/config: fc77ce4d0a8bd80a9a19df40023ad8bfc32af462e382c8419f6453f904a1514f
      labels:
        app.kubernetes.io/component: store-gateway
        app.kubernetes.io/instance: mimir-distributed
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/version: 2.10.4
        helm.sh/chart: mimir-distributed-5.1.3
        name: store-gateway-zone-c
        rollout-group: store-gateway
        zone: zone-c
      namespace: monitoring-system
    spec:
      affinity: {}
      containers:
      - args:
        - -target=store-gateway
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -store-gateway.sharding-ring.instance-availability-zone=zone-c
        env:
        - name: GOMAXPROCS
          value: "5"
        - name: GOMEMLIMIT
          value: "536870912"
        envFrom: null
        image: grafana/mimir:2.10.4
        imagePullPolicy: IfNotPresent
        livenessProbe: null
        name: store-gateway
        ports:
        - containerPort: 8080
          name: http-metrics
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 60
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /var/mimir
          name: runtime-config
        - mountPath: /data
          name: storage
        - mountPath: /active-query-tracker
          name: active-queries
      initContainers: []
      nodeSelector: {}
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: mimir-distributed
      terminationGracePeriodSeconds: 240
      tolerations: []
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: store-gateway
            app.kubernetes.io/instance: mimir-distributed
            app.kubernetes.io/name: mimir
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          items:
          - key: mimir.yaml
            path: mimir.yaml
          name: mimir-distributed-config
        name: config
      - configMap:
          name: mimir-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: active-queries
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: alertmanager
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-alertmanager
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: alertmanager
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: compactor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-compactor
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: compactor
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-distributor
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: distributor
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-ingester
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: ingester
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: nginx
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-nginx
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: nginx
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: overrides-exporter
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-overrides-exporter
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: overrides-exporter
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: querier
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-querier
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: querier
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-query-frontend
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: query-frontend
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-query-scheduler
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: query-scheduler
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: ruler
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-ruler
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: ruler
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: store-gateway
    app.kubernetes.io/instance: mimir-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.10.4
    helm.sh/chart: mimir-distributed-5.1.3
  name: mimir-distributed-store-gateway
  namespace: monitoring-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: store-gateway
      app.kubernetes.io/instance: mimir-distributed
      app.kubernetes.io/name: mimir
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app: mimir-distributed-make-bucket-job
    chart: mimir-distributed-5.1.3
    heritage: Helm
    release: mimir-distributed
  name: mimir-distributed-make-minio-buckets-5.0.7
  namespace: monitoring-system
spec:
  template:
    metadata:
      labels:
        app: mimir-distributed-job
        release: mimir-distributed
    spec:
      containers:
      - command:
        - /bin/sh
        - /config/initialize
        env:
        - name: MINIO_ENDPOINT
          value: mimir-distributed-minio
        - name: MINIO_PORT
          value: "9000"
        image: quay.io/minio/mc:RELEASE.2023-01-28T20-29-38Z
        imagePullPolicy: IfNotPresent
        name: minio-mc
        resources:
          requests:
            memory: 128Mi
        volumeMounts:
        - mountPath: /config
          name: minio-configuration
      restartPolicy: OnFailure
      volumes:
      - name: minio-configuration
        projected:
          sources:
          - configMap:
              name: mimir-distributed-minio
          - secret:
              name: mimir-distributed-minio
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: hook-succeeded,before-hook-creation
  labels:
    app: minio-post-job
    chart: minio-5.0.7
    heritage: Helm
    release: mimir-distributed
  name: mimir-distributed-minio-post-job
  namespace: monitoring-system
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: mimir-distributed
    spec:
      containers:
      - command:
        - /bin/sh
        - /config/initialize
        env:
        - name: MINIO_ENDPOINT
          value: mimir-distributed-minio
        - name: MINIO_PORT
          value: "9000"
        image: quay.io/minio/mc:RELEASE.2023-01-28T20-29-38Z
        imagePullPolicy: IfNotPresent
        name: minio-make-bucket
        resources:
          requests:
            memory: 128Mi
        volumeMounts:
        - mountPath: /config
          name: minio-configuration
      - command:
        - /bin/sh
        - /config/add-user
        env:
        - name: MINIO_ENDPOINT
          value: mimir-distributed-minio
        - name: MINIO_PORT
          value: "9000"
        image: quay.io/minio/mc:RELEASE.2023-01-28T20-29-38Z
        imagePullPolicy: IfNotPresent
        name: minio-make-user
        resources:
          requests:
            memory: 128Mi
        volumeMounts:
        - mountPath: /config
          name: minio-configuration
      restartPolicy: OnFailure
      volumes:
      - name: minio-configuration
        projected:
          sources:
          - configMap:
              name: mimir-distributed-minio
          - secret:
              name: mimir-distributed-minio
