apiVersion: v1
kind: Namespace
metadata:
  name: logging-system
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed
  namespace: logging-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana-agent
    app.kubernetes.io/version: v0.40.3
    helm.sh/chart: grafana-agent-0.37.0
  name: grafana-agent
  namespace: monitoring-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir
  namespace: monitoring-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana-agent
    app.kubernetes.io/version: v0.40.3
    helm.sh/chart: grafana-agent-0.37.0
  name: grafana-agent
rules:
- apiGroups:
  - ""
  - discovery.k8s.io
  - networking.k8s.io
  resources:
  - endpoints
  - endpointslices
  - ingresses
  - nodes
  - nodes/proxy
  - nodes/metrics
  - pods
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - pods
  - pods/log
  - namespaces
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - monitoring.grafana.com
  resources:
  - podlogs
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - monitoring.coreos.com
  resources:
  - prometheusrules
  verbs:
  - get
  - list
  - watch
- nonResourceURLs:
  - /metrics
  verbs:
  - get
- apiGroups:
  - monitoring.coreos.com
  resources:
  - podmonitors
  - servicemonitors
  - probes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - replicasets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - replicasets
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana-agent
    app.kubernetes.io/version: v0.40.3
    helm.sh/chart: grafana-agent-0.37.0
  name: grafana-agent
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: grafana-agent
subjects:
- kind: ServiceAccount
  name: grafana-agent
  namespace: monitoring-system
---
apiVersion: v1
data:
  LOKI_COMPACTOR_HOST: loki-distributed-compactor.logging-system.svc.cluster.local
  LOKI_DISTRIBUTOR_HOST: loki-distributed-distributor.logging-system.svc.cluster.local
  LOKI_INGESTER_HOST: loki-distributed-ingester.logging-system.svc.cluster.local
  LOKI_QUERIER_HOST: loki-distributed-querier.logging-system.svc.cluster.local
  LOKI_QUERY_FRONTEND_HOST: loki-distributed-query-frontend-headless.logging-system.svc.cluster.local
  LOKI_RULER_HOST: loki-distributed-ruler.logging-system.svc.cluster.local
kind: ConfigMap
metadata:
  name: nginx-env
  namespace: gateway
---
apiVersion: v1
data:
  config.yaml: |2-

    auth_enabled: false

    analytics:
     reporting_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9095
      log_level: info
      log_format: json


    # https://grafana.com/docs/loki/latest/configure/#use-environment-variables-in-the-configuration
    common:
      compactor_address: http://loki-distributed-compactor:3100
      replication_factor: 1
      storage:
        s3:
          bucketnames: loki-data
          endpoint: ${LOKI_S3_ENDPOINT:-minio.minio-system.svc:443}
          access_key_id: ${LOKI_S3_ACCESS_KEY_ID:-lgtmp}
          secret_access_key: ${LOKI_S3_SECRET_ACCESS_KEY:-supersecret}
          insecure: ${LOKI_S3_INSECURE:-false}
          s3forcepathstyle: true
          http_config:
            insecure_skip_verify: true

    compactor:
      working_directory: /tmp/compactor
      shared_store: s3
      compactor_ring:
        kvstore:
          store: memberlist

    distributor:
      ring:
        kvstore:
          store: memberlist

    frontend:
      log_queries_longer_than: 5s
      tail_proxy_url: http://loki-distributed-querier:3100
      scheduler_address: loki-distributed-query-scheduler:9095
    frontend_worker:
      scheduler_address: loki-distributed-query-scheduler:9095

    ingester:
      lifecycler:
        ring:
          kvstore:
            store: memberlist
      max_transfer_retries: 0
      wal:
        dir: /var/loki/wal

    limits_config:
      enforce_metric_name: false
      max_cache_freshness_per_query: 10m
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      split_queries_by_interval: 15m

    memberlist:
      join_members:
      - loki-distributed-memberlist

    query_range:
      align_queries_with_step: true
      cache_results: true
      results_cache:
        cache:
          memcached_client:
            addresses: "dns+memcached.memcached-system.svc:11211"
      cache_index_stats_results: true
      index_stats_results_cache:
        cache:
          memcached_client:
            addresses: "dns+memcached.memcached-system.svc:11211"

    ruler:
      ring:
        kvstore:
          store: memberlist
      storage:
        s3:
          bucketnames: loki-ruler
        type: s3

    runtime_config:
      file: /var/loki-distributed-runtime/runtime.yaml

    schema_config:
      configs:
      - from: "2023-08-01"
        index:
          period: 24h
          prefix: loki_index_
        object_store: s3
        schema: v13
        store: tsdb

    storage_config:
      tsdb_shipper:
        active_index_directory: /var/loki/index
        cache_location: /var/loki/cache
        index_gateway_client:
          server_address: dns:///loki-distributed-index-gateway:9095
        shared_store: s3

    chunk_store_config:
      chunk_cache_config:
        memcached_client:
          addresses: "dns+memcached.memcached-system.svc:11211"

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed
  namespace: logging-system
---
apiVersion: v1
data:
  runtime.yaml: |2

    {}
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-runtime
  namespace: logging-system
---
apiVersion: v1
data:
  config.river: "/*\nThe following example shows using the default all logs processing
    module, for\na single tenant and specifying the destination url/credentials via
    environment\nvariables.\n*/\nlogging {\n\tlevel  = coalesce(env(\"AGENT_LOG_LEVEL\"),
    \"info\")\n\tformat = \"logfmt\"\n}\n\n/********************************************\n
    * Grafana LGTMP Stack Receiver Provider\n ********************************************/\nmodule.file
    \"lgtmp\" {\n\tfilename = coalesce(env(\"AGENT_CONFIG_FOLDER\"), \"/etc/agent-modules\")
    + \"/lgtmp.river\"\n\n\targuments {\n\t\tcluster           = coalesce(env(\"CLUSTER\"),
    \"k3d-k3s-codelab\")\n\t\tlogs_endpoint     = coalesce(env(\"LOGS_ENDPOINT\"),
    \"http://nginx.gateway.svc:3100\")\n\t\tmetrics_endpoint  = coalesce(env(\"METRICS_ENDPOINT\"),
    \"http://nginx.gateway.svc:8080\")\n\t\tprofiles_endpoint = coalesce(env(\"PROFILES_ENDPOINT\"),
    \"http://nginx.gateway.svc:4040\")\n\t\ttraces_endpoint   = coalesce(env(\"TRACES_ENDPOINT\"),
    \"nginx.gateway.svc:4317\")\n\t}\n}\n\n/********************************************\n
    * Logs\n ********************************************/\nmodule.file \"logs_primary\"
    {\n\tfilename = coalesce(env(\"AGENT_CONFIG_FOLDER\"), \"/etc/agent-modules\")
    + \"/logs.river\"\n\n\targuments {\n\t\tforward_to    = [module.file.lgtmp.exports.logs_receiver]\n\t\tgit_repo
    \     = \"https://github.com/qclaogui/agent-modules.git\"\n\t\tgit_rev       =
    \"main\"\n\t\tgit_pull_freq = \"0s\"\n\t}\n}\n\n/********************************************\n
    * Metrics\n ********************************************/\nmodule.file \"metrics_primary\"
    {\n\tfilename = coalesce(env(\"AGENT_CONFIG_FOLDER\"), \"/etc/agent-modules\")
    + \"/metrics.river\"\n\n\targuments {\n\t\tforward_to = [module.file.lgtmp.exports.metrics_receiver]\n\t\tclustering
    = true\n\t}\n}\n\n/********************************************\n * Agent Integrations\n
    ********************************************/\nmodule.file \"agent_integrations\"
    {\n\tfilename = coalesce(env(\"AGENT_CONFIG_FOLDER\"), \"/etc/agent-modules\")
    + \"/integrations.river\"\n\n\targuments {\n\t\tname       = \"agent-integrations\"\n\t\tnamespace
    \ = \"monitoring-system\"\n\t\tforward_to = [module.file.lgtmp.exports.metrics_receiver]\n\t}\n}\n"
kind: ConfigMap
metadata:
  name: agent-config-6thf5hghkg
  namespace: monitoring-system
---
apiVersion: v1
data:
  MEMCACHED_SECRET_NAME: integrations-memcached
  MYSQL_SECRET_NAME: integrations-mysql
  REDIS_SECRET_NAME: integrations-redis
  memcached.river: "/*\nModule: Memcached integrations\nDescription: Wrapper module
    to integration Memcached metrics\n*/\nargument \"clustering\" {\n\t// comment
    = \"Whether or not clustering should be enabled\"\n\toptional = true\n\tdefault
    \ = true\n}\n\nargument \"name\" {\n\t// comment = \"Name of the secret for Memcached\"\n\toptional
    = true\n\tdefault  = \"integrations-memcached\"\n}\n\nargument \"namespace\" {\n\t//
    comment = \"Namespace of the Memcached secret Integrations\"\n\toptional = true\n\tdefault
    \ = \"default\"\n}\n\nargument \"instance\" {\n\t// comment  = \"Instance of the
    Memcached\"\n\toptional = true\n\tdefault  = \"primary\"\n}\n\nargument \"forward_to\"
    { }\n\nremote.kubernetes.secret \"memcached\" {\n\tname      = argument.name.value\n\tnamespace
    = argument.namespace.value\n}\n\n// Metrics\nprometheus.exporter.memcached \"integrations_memcached\"
    {\n\taddress = nonsensitive(remote.kubernetes.secret.memcached.data[\"memcached-address\"])\n\ttimeout
    = \"5s\"\n}\n\nprometheus.scrape \"memcached\" {\n\tclustering {\n\t\tenabled
    = argument.clustering.value\n\t}\n\n\tenable_protobuf_negotiation = true\n\tscrape_classic_histograms
    \  = true\n\n\ttargets = concat(\n\t\tprometheus.exporter.memcached.integrations_memcached.targets,\n\t)\n\tjob_name
    \  = \"integrations/memcached\"\n\tforward_to = [prometheus.relabel.integrations_memcached.receiver]\n}\n\nprometheus.relabel
    \"integrations_memcached\" {\n\trule {\n\t\treplacement  = argument.instance.value\n\t\ttarget_label
    = \"instance\"\n\t}\n\tforward_to = argument.forward_to.value\n}\n"
  mysql.river: "/*\nModule: Mysql integrations\nDescription: Wrapper module to integration
    mysql metrics\n*/\nargument \"clustering\" {\n\t// comment = \"Whether or not
    clustering should be enabled\"\n\toptional = true\n\tdefault  = true\n}\n\nargument
    \"name\" {\n\t// comment = \"Name of the secret for MySQL\"\n\toptional = true\n\tdefault
    \ = \"integrations-mysql\"\n}\n\nargument \"namespace\" {\n\t// comment = \"Namespace
    of the MySQL secret Integrations\"\n\toptional = true\n\tdefault  = \"default\"\n}\n\nargument
    \"instance\" {\n\t// comment  = \"Instance of the Database\"\n\toptional = true\n\tdefault
    \ = \"primary\"\n}\n\nargument \"forward_to\" { }\n\nremote.kubernetes.secret
    \"mysql\" {\n\tname      = argument.name.value\n\tnamespace = argument.namespace.value\n}\n\n//
    Metrics\nprometheus.exporter.mysql \"integrations_mysql\" {\n\tdata_source_name
    = nonsensitive(remote.kubernetes.secret.mysql.data[\"mysql-username\"]) + \":\"
    + nonsensitive(remote.kubernetes.secret.mysql.data[\"mysql-password\"]) + \"@(\"
    + nonsensitive(remote.kubernetes.secret.mysql.data[\"mysql-host\"]) + \")/\"\n}\n\nprometheus.scrape
    \"mysql\" {\n\tclustering {\n\t\tenabled = argument.clustering.value\n\t}\n\tenable_protobuf_negotiation
    = true\n\tscrape_classic_histograms   = true\n\n\ttargets = concat(\n\t\tprometheus.exporter.mysql.integrations_mysql.targets,\n\t)\n\tjob_name
    \  = \"integrations/mysql\"\n\tforward_to = [prometheus.relabel.integrations_mysql.receiver]\n}\n\nprometheus.relabel
    \"integrations_mysql\" {\n\trule {\n\t\treplacement  = argument.instance.value\n\t\ttarget_label
    = \"instance\"\n\t}\n\tforward_to = argument.forward_to.value\n}\n"
  redis.river: "/*\nModule: Redis integrations\nDescription: Wrapper module to integration
    Redis metrics\n*/\nargument \"clustering\" {\n\t// comment = \"Whether or not
    clustering should be enabled\"\n\toptional = true\n\tdefault  = true\n}\n\nargument
    \"namespace\" {\n\t// comment = \"Namespace of the Redis secret Integrations\"\n\toptional
    = true\n\tdefault  = \"default\"\n}\n\nargument \"name\" {\n\t// comment = \"Name
    of the secret for Redis\"\n\toptional = true\n\tdefault  = \"integrations-redis\"\n}\n\nargument
    \"instance\" {\n\t// comment  = \"Instance of the Redis\"\n\toptional = true\n\tdefault
    \ = \"master\"\n}\n\nargument \"forward_to\" { }\n\nremote.kubernetes.secret \"redis\"
    {\n\tname      = argument.name.value\n\tnamespace = argument.namespace.value\n}\n\n//
    Metrics\nprometheus.exporter.redis \"integrations_redis\" {\n\tredis_addr     =
    nonsensitive(remote.kubernetes.secret.redis.data[\"redis-addr\"])\n\tredis_password
    = nonsensitive(remote.kubernetes.secret.redis.data[\"redis-password\"])\n}\n\nprometheus.scrape
    \"redis\" {\n\tclustering {\n\t\tenabled = argument.clustering.value\n\t}\n\n\tenable_protobuf_negotiation
    = true\n\tscrape_classic_histograms   = true\n\n\ttargets = concat(\n\t\tprometheus.exporter.redis.integrations_redis.targets,\n\t)\n\tjob_name
    \  = \"integrations/redis\"\n\tforward_to = [prometheus.relabel.integrations_redis.receiver]\n}\n\nprometheus.relabel
    \"integrations_redis\" {\n\trule {\n\t\treplacement  = argument.instance.value\n\t\ttarget_label
    = \"instance\"\n\t}\n\tforward_to = argument.forward_to.value\n}\n"
kind: ConfigMap
metadata:
  name: agent-integrations
  namespace: monitoring-system
---
apiVersion: v1
data:
  integrations.river: "/*\nModule: Agent integrations\nDescription: Wrapper module
    to include auto loading integrations\n*/\nargument \"name\" {\n\t// comment =
    \"Name of the integrations config\"\n\toptional = true\n\tdefault  = \"agent-integrations\"\n}\n\nargument
    \"namespace\" {\n\t// comment = \"Namespace of the integrations config\"\n\toptional
    = true\n\tdefault  = \"default\"\n}\n\nargument \"forward_to\" { }\n\nremote.kubernetes.configmap
    \"integrations\" {\n\tname      = argument.name.value\n\tnamespace = argument.namespace.value\n}\n\n/********************************************\n
    * Integrations Mysql\n ********************************************/\nmodule.string
    \"mysql\" {\n\tcontent = remote.kubernetes.configmap.integrations.data[\"mysql.river\"]\n\n\targuments
    {\n\t\tnamespace  = argument.namespace.value\n\t\tname       = remote.kubernetes.configmap.integrations.data[\"MYSQL_SECRET_NAME\"]\n\t\tinstance
    \  = \"primary\"\n\t\tforward_to = argument.forward_to.value\n\t}\n}\n\n/********************************************\n
    * Integrations Memcached\n ********************************************/\nmodule.string
    \"memcached\" {\n\tcontent = remote.kubernetes.configmap.integrations.data[\"memcached.river\"]\n\n\targuments
    {\n\t\tnamespace  = argument.namespace.value\n\t\tname       = remote.kubernetes.configmap.integrations.data[\"MEMCACHED_SECRET_NAME\"]\n\t\tinstance
    \  = \"primary\"\n\t\tforward_to = argument.forward_to.value\n\t}\n}\n\n/********************************************\n
    * Integrations Redis\n ********************************************/\nmodule.string
    \"redis\" {\n\tcontent = remote.kubernetes.configmap.integrations.data[\"redis.river\"]\n\n\targuments
    {\n\t\tnamespace  = argument.namespace.value\n\t\tname       = remote.kubernetes.configmap.integrations.data[\"REDIS_SECRET_NAME\"]\n\t\tinstance
    \  = \"master\"\n\t\tforward_to = argument.forward_to.value\n\t}\n}\n"
  lgtmp.river: "/********************************************\n * ARGUMENTS\n ********************************************/\nargument
    \"cluster\" {\n\toptional = true\n\tdefault  = \"k3d-k3s-codelab\"\n}\n\nargument
    \"tenant\" {\n\toptional = true\n\tdefault  = \"anonymous\"\n}\n\nargument \"metrics_endpoint\"
    {\n\toptional = true\n\tdefault  = \"http://mimir:8080\"\n\t//comment = \"Where
    to send collected metrics.\"\n}\n\nargument \"logs_endpoint\" {\n\toptional =
    true\n\tdefault  = \"http://loki:3100\"\n\t//comment = \"Where to send collected
    logs.\"\n}\n\nargument \"traces_endpoint\" {\n\toptional = true\n\tdefault  =
    \"tempo:4317\"\n\t//comment = \"Where to send collected traces.\"\n}\n\nargument
    \"profiles_endpoint\" {\n\toptional = true\n\tdefault  = \"http://pyroscope:4040\"\n\t//comment
    \ = \"Where to send collected profiles.\"\n}\n\n/********************************************\n
    * EXPORTS\n ********************************************/\n\nexport \"metrics_receiver\"
    {\n\tvalue = prometheus.remote_write.mimir.receiver\n}\n\nexport \"logs_receiver\"
    {\n\tvalue = loki.write.loki.receiver\n}\n\nexport \"traces_receiver\" {\n\tvalue
    = otelcol.exporter.otlp.tempo.input\n}\n\nexport \"profiles_receiver\" {\n\tvalue
    = pyroscope.write.pyroscope.receiver\n}\n\n/********************************************\n
    * Endpoints\n ********************************************/\n\n// Metrics\nprometheus.remote_write
    \"mimir\" {\n\tendpoint {\n\t\turl                    = argument.metrics_endpoint.value
    + \"/api/v1/push\"\n\t\tsend_native_histograms = true\n\t}\n\n\texternal_labels
    = {\n\t\t\"scraped_by\" = \"grafana-agent\",\n\t\t\"cluster\"    = argument.cluster.value,\n\t}\n}\n\n//
    Logs\nloki.write \"loki\" {\n\tendpoint {\n\t\turl       = argument.logs_endpoint.value
    + \"/loki/api/v1/push\"\n\t\ttenant_id = argument.tenant.value\n\t}\n\n\texternal_labels
    = {\n\t\t\"scraped_by\" = \"grafana-agent\",\n\t\t\"cluster\"    = argument.cluster.value,\n\t}\n}\n\n//
    Traces\notelcol.exporter.otlp \"tempo\" {\n\tclient {\n\t\tendpoint = argument.traces_endpoint.value\n\n\t\ttls
    {\n\t\t\tinsecure             = true\n\t\t\tinsecure_skip_verify = true\n\t\t}\n\t}\n}\n\n//
    Profiles\npyroscope.write \"pyroscope\" {\n\tendpoint {\n\t\turl = argument.profiles_endpoint.value\n\t}\n\n\texternal_labels
    = {\n\t\t\"scraped_by\" = \"grafana-agent\",\n\t\t\"cluster\"    = argument.cluster.value,\n\t}\n}\n"
  logs.river: "/*\nModule: logs\nDescription: Wrapper module to include all kubernetes
    logging modules and use cri parsing\n*/\nargument \"forward_to\" {\n\t// comment
    = \"Must be a list(LogsReceiver) where collected logs should be forwarded to\"\n\toptional
    = false\n}\n\nargument \"tenant\" {\n\t// comment = \"The tenant to filter logs
    to.  This does not have to be the tenantId, this is the value to look for in the
    logs.agent.grafana.com/tenant annotation, and this can be a regex.\"\n\toptional
    = true\n\tdefault  = \".*\"\n}\n\nargument \"keep_labels\" {\n\t// comment = \"List
    of labels to keep before the log message is written to Loki\"\n\toptional = true\n\tdefault
    \ = [\n\t\t\"app\",\n\t\t\"cluster\",\n\t\t\"component\",\n\t\t\"container\",\n\t\t\"deployment\",\n\t\t\"env\",\n\t\t\"filename\",\n\t\t\"instance\",\n\t\t\"job\",\n\t\t\"level\",\n\t\t\"log_type\",\n\t\t\"namespace\",\n\t\t\"region\",\n\t\t\"service\",\n\t\t\"squad\",\n\t\t\"team\",\n\t]\n}\n\nargument
    \"git_repo\" {\n\toptional = true\n\tdefault  = coalesce(env(\"GIT_REPO\"), \"https://github.com/grafana/agent-modules.git\")\n}\n\nargument
    \"git_rev\" {\n\toptional = true\n\tdefault  = coalesce(env(\"GIT_REV\"), env(\"GIT_REVISION\"),
    env(\"GIT_BRANCH\"), \"main\")\n}\n\nargument \"git_pull_freq\" {\n\t// comment
    = \"How often to pull the git repo, the default is 0s which means never pull\"\n\toptional
    = true\n\tdefault  = \"0s\"\n}\n\nmodule.git \"log_targets\" {\n\trepository     =
    argument.git_repo.value\n\trevision       = argument.git_rev.value\n\tpull_frequency
    = argument.git_pull_freq.value\n\tpath           = \"modules/kubernetes/logs/targets/logs-from-worker.river\"\n\n\targuments
    {\n\t\tforward_to    = [module.git.log_formats_all.exports.process.receiver]\n\t\ttenant
    \       = argument.tenant.value\n\t\tgit_repo      = argument.git_repo.value\n\t\tgit_rev
    \      = argument.git_rev.value\n\t\tgit_pull_freq = argument.git_pull_freq.value\n\t}\n}\n\nmodule.git
    \"log_formats_all\" {\n\trepository     = argument.git_repo.value\n\trevision
    \      = argument.git_rev.value\n\tpull_frequency = argument.git_pull_freq.value\n\tpath
    \          = \"modules/kubernetes/logs/log-formats/all.river\"\n\n\targuments
    {\n\t\tforward_to    = [module.git.log_level_default.exports.process.receiver]\n\t\tgit_repo
    \     = argument.git_repo.value\n\t\tgit_rev       = argument.git_rev.value\n\t\tgit_pull_freq
    = argument.git_pull_freq.value\n\t}\n}\n\nmodule.git \"log_level_default\" {\n\trepository
    \    = argument.git_repo.value\n\trevision       = argument.git_rev.value\n\tpull_frequency
    = argument.git_pull_freq.value\n\tpath           = \"modules/kubernetes/logs/labels/log-level.river\"\n\n\targuments
    {\n\t\tforward_to = [module.git.label_normalize_filename.exports.process.receiver]\n\t}\n}\n\nmodule.git
    \"label_normalize_filename\" {\n\trepository     = argument.git_repo.value\n\trevision
    \      = argument.git_rev.value\n\tpull_frequency = argument.git_pull_freq.value\n\tpath
    \          = \"modules/kubernetes/logs/labels/normalize-filename.river\"\n\n\targuments
    {\n\t\t// here we fork, one branch goes to the log level module, the other goes
    to the metrics module\n\t\t// this is because we need to reduce the labels on
    the pre-metrics but they are still necessary in\n\t\t// downstream modules\n\t\tforward_to
    = [\n\t\t\tmodule.git.pre_process_metrics.exports.process.receiver,\n\t\t\tmodule.git.drop_levels.exports.process.receiver,\n\t\t]\n\t}\n}\n\nmodule.git
    \"pre_process_metrics\" {\n\trepository     = argument.git_repo.value\n\trevision
    \      = argument.git_rev.value\n\tpull_frequency = argument.git_pull_freq.value\n\tpath
    \          = \"modules/kubernetes/logs/metrics/pre-process-bytes-lines.river\"\n\n\targuments
    {\n\t\tforward_to  = [module.git.drop_levels.exports.process.receiver]\n\t\tkeep_labels
    = argument.keep_labels.value\n\t}\n}\n\nmodule.git \"drop_levels\" {\n\trepository
    \    = argument.git_repo.value\n\trevision       = argument.git_rev.value\n\tpull_frequency
    = argument.git_pull_freq.value\n\tpath           = \"modules/kubernetes/logs/drops/levels.river\"\n\n\targuments
    {\n\t\tforward_to    = [module.git.scrub_all.exports.process.receiver]\n\t\tgit_repo
    \     = argument.git_repo.value\n\t\tgit_rev       = argument.git_rev.value\n\t\tgit_pull_freq
    = argument.git_pull_freq.value\n\t}\n}\n\nmodule.git \"scrub_all\" {\n\trepository
    \    = argument.git_repo.value\n\trevision       = argument.git_rev.value\n\tpull_frequency
    = argument.git_pull_freq.value\n\tpath           = \"modules/kubernetes/logs/scrubs/all.river\"\n\n\targuments
    {\n\t\tforward_to    = [module.git.embed_pod.exports.process.receiver]\n\t\tgit_repo
    \     = argument.git_repo.value\n\t\tgit_rev       = argument.git_rev.value\n\t\tgit_pull_freq
    = argument.git_pull_freq.value\n\t}\n}\n\nmodule.git \"embed_pod\" {\n\trepository
    \    = argument.git_repo.value\n\trevision       = argument.git_rev.value\n\tpull_frequency
    = argument.git_pull_freq.value\n\tpath           = \"modules/kubernetes/logs/embed/pod.river\"\n\n\targuments
    {\n\t\tforward_to = [module.git.mask_all.exports.process.receiver]\n\t}\n}\n\nmodule.git
    \"mask_all\" {\n\trepository     = argument.git_repo.value\n\trevision       =
    argument.git_rev.value\n\tpull_frequency = argument.git_pull_freq.value\n\tpath
    \          = \"modules/kubernetes/logs/masks/all.river\"\n\n\targuments {\n\t\tforward_to
    \   = [module.git.label_keep.exports.process.receiver]\n\t\tgit_repo      = argument.git_repo.value\n\t\tgit_rev
    \      = argument.git_rev.value\n\t\tgit_pull_freq = argument.git_pull_freq.value\n\t}\n}\n\nmodule.git
    \"label_keep\" {\n\trepository     = argument.git_repo.value\n\trevision       =
    argument.git_rev.value\n\tpull_frequency = argument.git_pull_freq.value\n\tpath
    \          = \"modules/kubernetes/logs/labels/keep-labels.river\"\n\n\targuments
    {\n\t\tforward_to  = [module.git.post_process_metrics.exports.process.receiver]\n\t\tkeep_labels
    = argument.keep_labels.value\n\t}\n}\n\nmodule.git \"post_process_metrics\" {\n\trepository
    \    = argument.git_repo.value\n\trevision       = argument.git_rev.value\n\tpull_frequency
    = argument.git_pull_freq.value\n\tpath           = \"modules/kubernetes/logs/metrics/post-process-bytes-lines.river\"\n\n\targuments
    {\n\t\tforward_to = argument.forward_to.value\n\t}\n}\n"
  metrics.river: "/*\nModule: metrics-all\nDescription: Wrapper module to include
    all kubernetes metric modules and use cri parsing\n*/\nargument \"forward_to\"
    {\n\t// comment = \"Must be a list(MetricssReceiver) where collected logs should
    be forwarded to\"\n\toptional = false\n}\n\nargument \"clustering\" {\n\t// comment
    = \"Whether or not clustering should be enabled\"\n\toptional = true\n\tdefault
    \ = false\n}\n\n/********************************************\n * Kubernetes Auto
    Scrape ServiceMonitor\n ********************************************/\nprometheus.operator.servicemonitors
    \"auto_scrape_servicemonitors\" {\n\tforward_to = argument.forward_to.value\n\n\tclustering
    {\n\t\tenabled = argument.clustering.value\n\t}\n}\n\n/********************************************\n
    * Kubernetes Auto Scrape PodMonitors\n ********************************************/\nprometheus.operator.podmonitors
    \"auto_scrape_podmonitors\" {\n\tforward_to = argument.forward_to.value\n\n\tclustering
    {\n\t\tenabled = argument.clustering.value\n\t}\n\n\tselector {\n\t\tmatch_expression
    {\n\t\t\tkey      = \"team\"\n\t\t\toperator = \"In\"\n\t\t\tvalues   = [\"team-infra\"]\n\t\t}\n\t}\n}\n\n/********************************************\n
    * Kubernetes Prometheus Rules To Mimir\n ********************************************/\nmimir.rules.kubernetes
    \"prometheus_rules_to_mimir\" {\n\taddress   = coalesce(env(\"METRICS_ENDPOINT\"),
    \"http://nginx.gateway.svc:8080\")\n\ttenant_id = \"anonymous\"\n}\n"
  profiles.river: "/*\nModule: profiles\nDescription: Wrapper module to include all
    kubernetes profile modules and use cri parsing\n*/\nargument \"forward_to\" {\n\t//
    comment = \"Must be a list(ProfilessReceiver) where collected logs should be forwarded
    to\"\n\toptional = false\n}\n\nargument \"clustering\" {\n\t// comment = \"Whether
    or not clustering should be enabled\"\n\toptional = true\n\tdefault  = false\n}\n\ndiscovery.kubernetes
    \"pyroscope_kubernetes\" {\n\trole = \"pod\"\n}\n\n// The default scrape config
    allows to define annotations based scraping.\n//\n// For example the following
    annotations:\n//\n// ```\n// profiles.grafana.com/memory.scrape: \"true\"\n//
    profiles.grafana.com/memory.port: \"8080\"\n// profiles.grafana.com/cpu.scrape:
    \"true\"\n// profiles.grafana.com/cpu.port: \"8080\"\n// profiles.grafana.com/goroutine.scrape:
    \"true\"\n// profiles.grafana.com/goroutine.port: \"8080\"\n// ```\n//\n// will
    scrape the `memory`, `cpu` and `goroutine` profiles from the `8080` port of the
    pod.\n//\n// For more information see https://grafana.com/docs/phlare/latest/operators-guide/deploy-kubernetes/#optional-scrape-your-own-workloads-profiles\ndiscovery.relabel
    \"kubernetes_pods\" {\n\ttargets = concat(discovery.kubernetes.pyroscope_kubernetes.targets)\n\n\trule
    {\n\t\taction        = \"drop\"\n\t\tsource_labels = [\"__meta_kubernetes_pod_phase\"]\n\t\tregex
    \        = \"Pending|Succeeded|Failed|Completed\"\n\t}\n\n\trule {\n\t\taction
    = \"labelmap\"\n\t\tregex  = \"__meta_kubernetes_pod_label_(.+)\"\n\t}\n\n\trule
    {\n\t\taction        = \"replace\"\n\t\tsource_labels = [\"__meta_kubernetes_namespace\"]\n\t\ttarget_label
    \ = \"namespace\"\n\t}\n\n\trule {\n\t\taction        = \"replace\"\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_name\"]\n\t\ttarget_label  = \"pod\"\n\t}\n\n\trule
    {\n\t\taction        = \"replace\"\n\t\tsource_labels = [\"__meta_kubernetes_pod_container_name\"]\n\t\ttarget_label
    \ = \"container\"\n\t}\n}\n\ndiscovery.relabel \"kubernetes_pods_memory_default_name\"
    {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_memory_custom_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name\"]\n\t\taction
    \       = \"drop\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name\"\n\t\taction
    \       = \"keepequal\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\n/********************************************\n
    * Kubernetes Pyroscope Scrape Memory\n ********************************************/\npyroscope.scrape
    \"pyroscope_scrape_memory\" {\n\tclustering {\n\t\tenabled = argument.clustering.value\n\t}\n\n\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_memory_default_name.output, discovery.relabel.kubernetes_pods_memory_custom_name.output)\n\tforward_to
    = argument.forward_to.value\n\n\tprofiling_config {\n\t\tprofile.memory {\n\t\t\tenabled
    = true\n\t\t}\n\n\t\tprofile.process_cpu {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.goroutine
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.block {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.mutex
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.fgprof {\n\t\t\tenabled = false\n\t\t}\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_cpu_default_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_cpu_custom_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name\"]\n\t\taction
    \       = \"drop\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name\"\n\t\taction
    \       = \"keepequal\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\n/********************************************\n
    * Kubernetes Pyroscope Scrape CPU\n ********************************************/\npyroscope.scrape
    \"pyroscope_scrape_cpu\" {\n\tclustering {\n\t\tenabled = argument.clustering.value\n\t}\n\n\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_cpu_default_name.output, discovery.relabel.kubernetes_pods_cpu_custom_name.output)\n\tforward_to
    = argument.forward_to.value\n\n\tprofiling_config {\n\t\tprofile.memory {\n\t\t\tenabled
    = false\n\t\t}\n\n\t\tprofile.process_cpu {\n\t\t\tenabled = true\n\t\t}\n\n\t\tprofile.goroutine
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.block {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.mutex
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.fgprof {\n\t\t\tenabled = false\n\t\t}\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_goroutine_default_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_goroutine_custom_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name\"]\n\t\taction
    \       = \"drop\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name\"\n\t\taction
    \       = \"keepequal\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\n/********************************************\n
    * Kubernetes Pyroscope Scrape Goroutine\n ********************************************/\npyroscope.scrape
    \"pyroscope_scrape_goroutine\" {\n\tclustering {\n\t\tenabled = argument.clustering.value\n\t}\n\n\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_goroutine_default_name.output,
    discovery.relabel.kubernetes_pods_goroutine_custom_name.output)\n\tforward_to
    = argument.forward_to.value\n\n\tprofiling_config {\n\t\tprofile.memory {\n\t\t\tenabled
    = false\n\t\t}\n\n\t\tprofile.process_cpu {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.goroutine
    {\n\t\t\tenabled = true\n\t\t}\n\n\t\tprofile.block {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.mutex
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.fgprof {\n\t\t\tenabled = false\n\t\t}\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_block_default_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_block_custom_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name\"]\n\t\taction
    \       = \"drop\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name\"\n\t\taction
    \       = \"keepequal\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\n/********************************************\n
    * Kubernetes Pyroscope Scrape Block\n ********************************************/\npyroscope.scrape
    \"pyroscope_scrape_block\" {\n\tclustering {\n\t\tenabled = argument.clustering.value\n\t}\n\n\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_block_default_name.output, discovery.relabel.kubernetes_pods_block_custom_name.output)\n\tforward_to
    = argument.forward_to.value\n\n\tprofiling_config {\n\t\tprofile.memory {\n\t\t\tenabled
    = false\n\t\t}\n\n\t\tprofile.process_cpu {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.goroutine
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.block {\n\t\t\tenabled = true\n\t\t}\n\n\t\tprofile.mutex
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.fgprof {\n\t\t\tenabled = false\n\t\t}\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_mutex_default_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_mutex_custom_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name\"]\n\t\taction
    \       = \"drop\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name\"\n\t\taction
    \       = \"keepequal\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\n/********************************************\n
    * Kubernetes Pyroscope Scrape Mutex\n ********************************************/\npyroscope.scrape
    \"pyroscope_scrape_mutex\" {\n\tclustering {\n\t\tenabled = argument.clustering.value\n\t}\n\n\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_mutex_default_name.output, discovery.relabel.kubernetes_pods_mutex_custom_name.output)\n\tforward_to
    = argument.forward_to.value\n\n\tprofiling_config {\n\t\tprofile.memory {\n\t\t\tenabled
    = false\n\t\t}\n\n\t\tprofile.process_cpu {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.goroutine
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.block {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.mutex
    {\n\t\t\tenabled = true\n\t\t}\n\n\t\tprofile.fgprof {\n\t\t\tenabled = false\n\t\t}\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_fgprof_default_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\ndiscovery.relabel
    \"kubernetes_pods_fgprof_custom_name\" {\n\ttargets = concat(discovery.relabel.kubernetes_pods.output)\n\n\trule
    {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scrape\"]\n\t\taction
    \       = \"keep\"\n\t\tregex         = \"true\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name\"]\n\t\taction
    \       = \"drop\"\n\t\tregex         = \"\"\n\t}\n\n\trule {\n\t\tsource_labels
    = [\"__meta_kubernetes_pod_container_port_name\"]\n\t\ttarget_label  = \"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name\"\n\t\taction
    \       = \"keepequal\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scheme\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(https?)\"\n\t\ttarget_label  = \"__scheme__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_path\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+)\"\n\t\ttarget_label  = \"__profile_path__\"\n\t\treplacement
    \  = \"$1\"\n\t}\n\n\trule {\n\t\tsource_labels = [\"__address__\", \"__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port\"]\n\t\taction
    \       = \"replace\"\n\t\tregex         = \"(.+?)(?::\\\\d+)?;(\\\\d+)\"\n\t\ttarget_label
    \ = \"__address__\"\n\t\treplacement   = \"$1:$2\"\n\t}\n}\n\n/********************************************\n
    * Kubernetes Pyroscope Scrape Fgprof\n ********************************************/\npyroscope.scrape
    \"pyroscope_scrape_fgprof\" {\n\tclustering {\n\t\tenabled = argument.clustering.value\n\t}\n\n\ttargets
    \   = concat(discovery.relabel.kubernetes_pods_fgprof_default_name.output, discovery.relabel.kubernetes_pods_fgprof_custom_name.output)\n\tforward_to
    = argument.forward_to.value\n\n\tprofiling_config {\n\t\tprofile.memory {\n\t\t\tenabled
    = false\n\t\t}\n\n\t\tprofile.process_cpu {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.goroutine
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.block {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.mutex
    {\n\t\t\tenabled = false\n\t\t}\n\n\t\tprofile.fgprof {\n\t\t\tenabled = true\n\t\t}\n\t}\n}\n"
  traces.river: "/*\nModule: traces\n*/\n\n/********************************************\n
    * ARGUMENTS\n ********************************************/\nargument \"traces_forward_to\"
    {\n\toptional = false\n}\n\nargument \"logs_forward_to\" {\n\toptional = false\n}\n\nargument
    \"metrics_forward_to\" {\n\toptional = false\n}\n\nargument \"cluster\" {\n\toptional
    = true\n\tdefault  = \"k3d-k3s-codelab\"\n}\n\nargument \"otlp_http_endpoint\"
    {\n\toptional = true\n\tdefault  = \"0.0.0.0:4318\"\n}\n\nargument \"otlp_grpc_endpoint\"
    {\n\toptional = true\n\tdefault  = \"0.0.0.0:4317\"\n}\n\n/********************************************\n
    * EXPORTS\n ********************************************/\nexport \"agent_traces_input\"
    {\n\tvalue = otelcol.processor.batch.default.input\n}\n\n/********************************************\n
    * Jaeger for Metrics Logs Traces\n ********************************************/\n\notelcol.receiver.jaeger
    \"default\" {\n\tprotocols {\n\t\tgrpc {\n\t\t\tendpoint = \"0.0.0.0:14250\"\n\t\t}\n\n\t\tthrift_http
    {\n\t\t\tendpoint = \"0.0.0.0:14268\"\n\t\t}\n\n\t\tthrift_binary {\n\t\t\tendpoint
    = \"0.0.0.0:6832\"\n\t\t}\n\n\t\tthrift_compact {\n\t\t\tendpoint = \"0.0.0.0:6831\"\n\t\t}\n\t}\n\n\toutput
    {\n\t\tmetrics = [otelcol.processor.batch.default.input]\n\t\tlogs    = [otelcol.processor.resourcedetection.default.input]\n\t\ttraces
    \ = [otelcol.processor.resourcedetection.default.input]\n\t}\n}\n\n/********************************************\n
    * Otelcol for Metrics Logs Traces\n ********************************************/\n//
    https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.receiver.otlp/\notelcol.receiver.otlp
    \"default\" {\n\tgrpc {\n\t\tendpoint = argument.otlp_grpc_endpoint.value\n\t}\n\n\thttp
    {\n\t\tendpoint = argument.otlp_http_endpoint.value\n\t}\n\n\toutput {\n\t\tmetrics
    = [otelcol.processor.batch.default.input]\n\t\tlogs    = [otelcol.processor.resourcedetection.default.input]\n\t\ttraces
    \ = [\n\t\t\totelcol.processor.resourcedetection.default.input,\n\t\t\totelcol.connector.spanlogs.autologging.input,\n\t\t]\n\t}\n}\n\notelcol.processor.resourcedetection
    \"default\" {\n\tdetectors = [\"env\"]\n\n\toutput {\n\t\tlogs   = [otelcol.processor.k8sattributes.default.input]\n\t\ttraces
    = [otelcol.processor.k8sattributes.default.input]\n\t}\n}\n\notelcol.processor.k8sattributes
    \"default\" {\n\textract {\n\t\tmetadata = [\n\t\t\t\"k8s.namespace.name\",\n\t\t\t\"k8s.pod.name\",\n\t\t\t\"k8s.deployment.name\",\n\t\t\t\"k8s.statefulset.name\",\n\t\t\t\"k8s.daemonset.name\",\n\t\t\t\"k8s.cronjob.name\",\n\t\t\t\"k8s.job.name\",\n\t\t\t\"k8s.node.name\",\n\t\t\t\"k8s.pod.uid\",\n\t\t\t\"k8s.pod.start_time\",\n\t\t]\n\t}\n\n\tpod_association
    {\n\t\tsource {\n\t\t\tfrom = \"connection\"\n\t\t}\n\t}\n\n\toutput {\n\t\tlogs
    \  = [otelcol.processor.transform.add_resource_attributes.input]\n\t\ttraces =
    [otelcol.processor.transform.add_resource_attributes.input]\n\t}\n}\n\notelcol.processor.transform
    \"add_resource_attributes\" {\n\terror_mode = \"ignore\"\n\n\tlog_statements {\n\t\tcontext
    \   = \"resource\"\n\t\tstatements = [\n\t\t\t`set(attributes[\"pod\"], attributes[\"k8s.pod.name\"])`,\n\t\t\t`set(attributes[\"namespace\"],
    attributes[\"k8s.namespace.name\"])`,\n\t\t\t`set(attributes[\"loki.resource.labels\"],
    \"pod, namespace, cluster, job\")`,\n\t\t\t`set(attributes[\"k8s.cluster.name\"],
    \"k3d-k3s-codelab\") where attributes[\"k8s.cluster.name\"] == nil`,\n\t\t]\n\t}\n\n\ttrace_statements
    {\n\t\tcontext    = \"resource\"\n\t\tstatements = [\n\t\t\t`set(attributes[\"k8s.cluster.name\"],
    \"k3d-k3s-codelab\") where attributes[\"k8s.cluster.name\"] == nil`,\n\t\t]\n\t}\n\n\toutput
    {\n\t\tlogs   = [otelcol.processor.filter.default.input]\n\t\ttraces = [otelcol.processor.filter.default.input]\n\t}\n}\n\notelcol.processor.filter
    \"default\" {\n\terror_mode = \"ignore\"\n\n\toutput {\n\t\tlogs   = [otelcol.processor.batch.default.input]\n\t\ttraces
    = [otelcol.processor.batch.default.input]\n\t}\n}\n\notelcol.processor.batch \"default\"
    {\n\tsend_batch_size     = 16384\n\tsend_batch_max_size = 0\n\ttimeout             =
    \"5s\"\n\n\toutput {\n\t\tmetrics = [otelcol.processor.memory_limiter.default.input]\n\t\tlogs
    \   = [otelcol.processor.memory_limiter.default.input]\n\t\ttraces  = [otelcol.processor.memory_limiter.default.input]\n\t}\n}\n\notelcol.processor.memory_limiter
    \"default\" {\n\tcheck_interval         = \"1s\"\n\tlimit_percentage       = 50\n\tspike_limit_percentage
    = 30\n\n\toutput {\n\t\tmetrics = [otelcol.exporter.prometheus.tracesmetrics.input]\n\t\tlogs
    \   = [otelcol.exporter.loki.traceslogs.input]\n\t\ttraces  = argument.traces_forward_to.value\n\t}\n}\n\notelcol.exporter.prometheus
    \"tracesmetrics\" {\n\tforward_to = argument.metrics_forward_to.value\n}\n\notelcol.exporter.loki
    \"traceslogs\" {\n\tforward_to = [loki.process.traceslogs.receiver]\n}\n\n// The
    OpenTelemetry spanlog connector processes incoming trace spans and extracts data
    from them ready\n// for logging.\notelcol.connector.spanlogs \"autologging\" {\n\t//
    We only want to output a line for each root span (ie. every single trace), and
    not for every\n\t// process or span (outputting a line for every span would be
    extremely verbose).\n\tspans     = false\n\troots     = true\n\tprocesses = false\n\n\t//
    We want to ensure that the following three span attributes are included in the
    log line, if present.\n\tspan_attributes = [\n\t\t\"http.method\",\n\t\t\"http.target\",\n\t\t\"http.status_code\",\n\t]\n\n\t//
    Overrides the default key in the log line to be `traceId`, which is then used
    by Grafana to\n\t// identify the trace ID for correlation with the Tempo datasource.\n\toverrides
    {\n\t\ttrace_id_key = \"traceId\"\n\t}\n\n\t// Send to the OpenTelemetry Loki
    exporter.\n\toutput {\n\t\tlogs = [otelcol.exporter.loki.autologging.input]\n\t}\n}\n\n//
    Simply forwards the incoming OpenTelemetry log format out as a Loki log.\n// We
    need this stage to ensure we can then process the logline as a Loki object.\notelcol.exporter.loki
    \"autologging\" {\n\tforward_to = [loki.process.autologging.receiver]\n}\n\n//
    The Loki processor allows us to accept a correctly formatted Loki log and mutate
    it into\n// a set of fields for output.\nloki.process \"autologging\" {\n\t//
    The JSON stage simply extracts the `body` (the actual logline) from the Loki log,
    ignoring\n\t// all other fields.\n\tstage.json {\n\t\texpressions = {\"body\"
    = \"\"}\n\t}\n\t// The output stage takes the body (the main logline) and uses
    this as the source for the output\n\t// logline. In this case, it essentially
    turns it into logfmt.\n\tstage.output {\n\t\tsource = \"body\"\n\t}\n\n\tforward_to
    = [loki.process.traceslogs.receiver]\n}\n\nloki.process \"traceslogs\" {\n\tstage.tenant
    {\n\t\tvalue = \"anonymous\"\n\t}\n\n\tforward_to = argument.logs_forward_to.value\n}\n"
kind: ConfigMap
metadata:
  name: agent-modules-cf8t5bf7t9
  namespace: monitoring-system
---
apiVersion: v1
data:
  alertmanager_fallback_config.yaml: |
    route:
      group_wait: 0s
      receiver: empty-receiver

    receivers:
      # In this example we're not going to send any notification out of Alertmanager.
      - name: 'empty-receiver'
  mimir.yaml: |
    # Do not use this configuration in production.
    # It is for demonstration purposes only.
    multitenancy_enabled: false

    # -usage-stats.enabled=false
    usage_stats:
      enabled: false

    server:
      http_listen_port: 8080
      grpc_listen_port: 9095
      log_level: info

    # https://grafana.com/docs/mimir/latest/references/configuration-parameters/#use-environment-variables-in-the-configuration
    common:
      storage:
        backend: s3
        s3:
          endpoint:          ${MIMIR_S3_ENDPOINT:minio.minio-system.svc:443}
          access_key_id:     ${MIMIR_S3_ACCESS_KEY_ID:lgtmp}
          secret_access_key: ${MIMIR_S3_SECRET_ACCESS_KEY:supersecret}
          insecure:          ${MIMIR_S3_INSECURE:false}
          http:
            insecure_skip_verify: true

    alertmanager:
      data_dir: /data/alertmanager
      enable_api: true
      external_url: /alertmanager
      fallback_config_file: /etc/mimir/alertmanager_fallback_config.yaml
    alertmanager_storage:
      s3:
        bucket_name: mimir-alertmanager


    memberlist:
      join_members: [ mimir-memberlist:7946 ]

    ingester:
      ring:
        replication_factor: 1

    store_gateway:
      sharding_ring:
        replication_factor: 1


    blocks_storage:
      s3:
        bucket_name: mimir-blocks
      tsdb:
        dir: /data/ingester
        ship_interval: 1m
        block_ranges_period: [ 2h ]
        retention_period: 3h
      bucket_store:
        index_cache:
          backend: memcached
          memcached:
            addresses: dns+memcached.memcached-system.svc:11211

        chunks_cache:
          backend: memcached
          memcached:
            addresses: dns+memcached.memcached-system.svc:11211

        metadata_cache:
          backend: memcached
          memcached:
            addresses: dns+memcached.memcached-system.svc:11211

    ruler:
      rule_path: /data/rules
      enable_api: true
      alertmanager_url: http://localhost:8080/alertmanager
    ruler_storage:
      s3:
        bucket_name: mimir-ruler
      cache:
        backend: memcached
        memcached:
          addresses: dns+memcached.memcached-system.svc:11211

    compactor:
      compaction_interval: 30s
      data_dir: /data/mimir-compactor
      cleanup_interval:    1m
      tenant_cleanup_delay: 1m

    limits:
      native_histograms_ingestion_enabled: true

    overrides_exporter:
      ring:
        enabled: true
        wait_stability_min_duration: 30s

    runtime_config:
      file: /etc/mimir/runtime.yaml
  runtime.yaml: |-
    # This file can be used to set overrides or other runtime config.
    ingester_limits: # limits that each ingester replica enforces
      max_ingestion_rate: 20000
      max_series: 1500000
      max_tenants: 1000
      max_inflight_push_requests: 30000

    distributor_limits: # limits that each distributor replica enforces
      max_ingestion_rate: 20000
      max_inflight_push_requests: 30000
      max_inflight_push_requests_bytes: 50000000

    overrides:
      anonymous: # limits for anonymous that the whole cluster enforces
        # ingestion_tenant_shard_size: 9
        max_global_series_per_user: 1500000
        max_fetched_series_per_query: 100000
        native_histograms_ingestion_enabled: true
        ruler_max_rules_per_rule_group: 50
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir-config-958c4gm5k9
  namespace: monitoring-system
---
apiVersion: v1
data:
  LOKI_S3_SECRET_ACCESS_KEY: VkQ1MzhPWXhTRWlHRDRJOW1tRmZxRk1DR3ExdklpR20=
kind: Secret
metadata:
  name: loki-distributed-env-58m52b99kc
  namespace: logging-system
type: Opaque
---
apiVersion: v1
data:
  memcached-address: bWVtY2FjaGVkLm1lbWNhY2hlZC1zeXN0ZW0uc3ZjLmNsdXN0ZXIubG9jYWw6MTEyMTE=
kind: Secret
metadata:
  name: integrations-memcached
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
data:
  mysql-host: bXlzcWwubXlzcWwtc3lzdGVtLnN2Yy5jbHVzdGVyLmxvY2Fs
  mysql-password: VkQ1MzhPWXhTRWlHRDRJOW1tRmZxRk1DR3ExdklpR20=
  mysql-username: bGd0bXA=
kind: Secret
metadata:
  name: integrations-mysql
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
data:
  redis-addr: cmVkaXMtbWFzdGVyLnJlZGlzLXN5c3RlbS5zdmMuY2x1c3Rlci5sb2NhbDo2Mzc5
  redis-password: VkQ1MzhPWXhTRWlHRDRJOW1tRmZxRk1DR3ExdklpR20=
kind: Secret
metadata:
  name: integrations-redis
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
data:
  MIMIR_S3_SECRET_ACCESS_KEY: VkQ1MzhPWXhTRWlHRDRJOW1tRmZxRk1DR3ExdklpR20=
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir-env-92ddctt858
  namespace: monitoring-system
type: Opaque
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: compactor
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-compactor
  namespace: logging-system
spec:
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: compactor
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-distributor
  namespace: logging-system
spec:
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: index-gateway
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-index-gateway
  namespace: logging-system
spec:
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: index-gateway
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: index-gateway
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
    prometheus.io/service-monitor: "false"
  name: loki-distributed-index-gateway-headless
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: index-gateway
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-ingester
  namespace: logging-system
spec:
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
    prometheus.io/service-monitor: "false"
  name: loki-distributed-ingester-headless
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-memberlist
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: tcp
    port: 7946
    protocol: TCP
    targetPort: http-memberlist
  selector:
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/part-of: memberlist
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: querier
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-querier
  namespace: logging-system
spec:
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: querier
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-query-frontend
  namespace: logging-system
spec:
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  - name: grpclb
    port: 9096
    protocol: TCP
    targetPort: grpc
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
    prometheus.io/service-monitor: "false"
  name: loki-distributed-query-frontend-headless
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  - name: grpclb
    port: 9096
    protocol: TCP
    targetPort: grpc
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-query-scheduler
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpclb
    port: 9095
    protocol: TCP
    targetPort: grpc
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ruler
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  name: loki-distributed-ruler
  namespace: logging-system
spec:
  clusterIP: None
  ports:
  - name: http
    port: 3100
    protocol: TCP
    targetPort: http
  - name: grpc
    port: 9095
    protocol: TCP
    targetPort: grpc
  selector:
    app.kubernetes.io/component: ruler
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/name: loki-distributed
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana-agent
    app.kubernetes.io/version: v0.40.3
    helm.sh/chart: grafana-agent-0.37.0
  name: grafana-agent
  namespace: monitoring-system
spec:
  internalTrafficPolicy: Cluster
  ports:
  - name: http-metrics
    port: 80
    protocol: TCP
    targetPort: 80
  - name: grpc-otlp
    port: 4317
    protocol: TCP
    targetPort: 4317
  - name: http-otlp
    port: 4318
    protocol: TCP
    targetPort: 4318
  - name: zipkin
    port: 9411
    protocol: TCP
    targetPort: 9411
  - name: jaeger-compact
    port: 6831
    protocol: UDP
    targetPort: 6831
  selector:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/name: grafana-agent
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana-agent
    app.kubernetes.io/version: v0.40.3
    helm.sh/chart: grafana-agent-0.37.0
  name: grafana-agent-cluster
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
  - name: grpc-otlp
    port: 4317
    protocol: TCP
    targetPort: 4317
  - name: http-otlp
    port: 4318
    protocol: TCP
    targetPort: 4318
  - name: zipkin
    port: 9411
    protocol: TCP
    targetPort: 9411
  - name: jaeger-compact
    port: 6831
    protocol: UDP
    targetPort: 6831
  selector:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/name: grafana-agent
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir
  namespace: monitoring-system
spec:
  ports:
  - name: http-metrics
    port: 8080
  - name: grpc-distribut
    port: 9095
  selector:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/name: mimir
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
    prometheus.io/service-monitor: "false"
  name: mimir-memberlist
  namespace: monitoring-system
spec:
  clusterIP: None
  ports:
  - appProtocol: tcp
    name: tcp-gossip-ring
    port: 7946
    protocol: TCP
    targetPort: 7946
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: distributor
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-distributor
  namespace: logging-system
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: distributor
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  template:
    metadata:
      annotations:
        checksum/config: 684b1417c17a8d288d9276d1cc63260075683c560c3f2eb7eb8e881ae03ba479
      labels:
        app.kubernetes.io/component: distributor
        app.kubernetes.io/instance: loki-distributed
        app.kubernetes.io/name: loki-distributed
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: distributor
                  app.kubernetes.io/instance: loki-distributed
                  app.kubernetes.io/name: loki-distributed
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: distributor
                app.kubernetes.io/instance: loki-distributed
                app.kubernetes.io/name: loki-distributed
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=distributor
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-distributed-env-58m52b99kc
        image: docker.io/grafana/loki:2.9.6
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 300
        name: distributor
        ports:
        - containerPort: 3100
          name: http
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /var/loki-distributed-runtime
          name: runtime-config
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki-distributed
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          name: loki-distributed
        name: config
      - configMap:
          name: loki-distributed-runtime
        name: runtime-config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: querier
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-querier
  namespace: logging-system
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: querier
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  template:
    metadata:
      annotations:
        checksum/config: 684b1417c17a8d288d9276d1cc63260075683c560c3f2eb7eb8e881ae03ba479
      labels:
        app.kubernetes.io/component: querier
        app.kubernetes.io/instance: loki-distributed
        app.kubernetes.io/name: loki-distributed
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: querier
                  app.kubernetes.io/instance: loki-distributed
                  app.kubernetes.io/name: loki-distributed
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: querier
                app.kubernetes.io/instance: loki-distributed
                app.kubernetes.io/name: loki-distributed
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=querier
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-distributed-env-58m52b99kc
        image: docker.io/grafana/loki:2.9.6
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 300
        name: querier
        ports:
        - containerPort: 3100
          name: http
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /var/loki-distributed-runtime
          name: runtime-config
        - mountPath: /var/loki
          name: data
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki-distributed
      terminationGracePeriodSeconds: 30
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: querier
            app.kubernetes.io/instance: loki-distributed
            app.kubernetes.io/name: loki-distributed
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          name: loki-distributed
        name: config
      - configMap:
          name: loki-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: data
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: query-frontend
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-query-frontend
  namespace: logging-system
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: query-frontend
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  template:
    metadata:
      annotations:
        checksum/config: 684b1417c17a8d288d9276d1cc63260075683c560c3f2eb7eb8e881ae03ba479
      labels:
        app.kubernetes.io/component: query-frontend
        app.kubernetes.io/instance: loki-distributed
        app.kubernetes.io/name: loki-distributed
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: query-frontend
                  app.kubernetes.io/instance: loki-distributed
                  app.kubernetes.io/name: loki-distributed
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: query-frontend
                app.kubernetes.io/instance: loki-distributed
                app.kubernetes.io/name: loki-distributed
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=query-frontend
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-distributed-env-58m52b99kc
        image: docker.io/grafana/loki:2.9.6
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 300
        name: query-frontend
        ports:
        - containerPort: 3100
          name: http
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /var/loki-distributed-runtime
          name: runtime-config
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki-distributed
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          name: loki-distributed
        name: config
      - configMap:
          name: loki-distributed-runtime
        name: runtime-config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-query-scheduler
  namespace: logging-system
spec:
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: query-scheduler
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  template:
    metadata:
      annotations:
        checksum/config: 684b1417c17a8d288d9276d1cc63260075683c560c3f2eb7eb8e881ae03ba479
      labels:
        app.kubernetes.io/component: query-scheduler
        app.kubernetes.io/instance: loki-distributed
        app.kubernetes.io/name: loki-distributed
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: query-scheduler
                  app.kubernetes.io/instance: loki-distributed
                  app.kubernetes.io/name: loki-distributed
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: query-scheduler
                app.kubernetes.io/instance: loki-distributed
                app.kubernetes.io/name: loki-distributed
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=query-scheduler
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-distributed-env-58m52b99kc
        image: docker.io/grafana/loki:2.9.6
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 300
        name: query-scheduler
        ports:
        - containerPort: 3100
          name: http
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 1
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /var/loki-distributed-runtime
          name: runtime-config
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki-distributed
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          name: loki-distributed
        name: config
      - configMap:
          name: loki-distributed-runtime
        name: runtime-config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: ruler
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-ruler
  namespace: logging-system
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: ruler
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  template:
    metadata:
      annotations:
        checksum/config: 684b1417c17a8d288d9276d1cc63260075683c560c3f2eb7eb8e881ae03ba479
      labels:
        app.kubernetes.io/component: ruler
        app.kubernetes.io/instance: loki-distributed
        app.kubernetes.io/name: loki-distributed
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: ruler
                  app.kubernetes.io/instance: loki-distributed
                  app.kubernetes.io/name: loki-distributed
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: ruler
                app.kubernetes.io/instance: loki-distributed
                app.kubernetes.io/name: loki-distributed
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=ruler
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-distributed-env-58m52b99kc
        image: docker.io/grafana/loki:2.9.6
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 300
        name: ruler
        ports:
        - containerPort: 3100
          name: http
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /var/loki-distributed-runtime
          name: runtime-config
        - mountPath: /var/loki
          name: data
        - mountPath: /tmp/loki
          name: tmp
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki-distributed
      terminationGracePeriodSeconds: 300
      volumes:
      - configMap:
          name: loki-distributed
        name: config
      - configMap:
          name: loki-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: tmp
      - emptyDir: {}
        name: data
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.11.0
  name: mimir
  namespace: monitoring-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: mimir
      app.kubernetes.io/instance: mimir-monolithic-mode
      app.kubernetes.io/name: mimir
      app.kubernetes.io/part-of: memberlist
  template:
    metadata:
      annotations:
        logs.agent.grafana.com/scrape: "true"
        logs.agent.grafana.com/scrub-level: info
        profiles.grafana.com/cpu.port_name: http-metrics
        profiles.grafana.com/cpu.scrape: "false"
        profiles.grafana.com/goroutine.port_name: http-metrics
        profiles.grafana.com/goroutine.scrape: "false"
        profiles.grafana.com/memory.port_name: http-metrics
        profiles.grafana.com/memory.scrape: "false"
        pyroscope.io/service_name: mimir
      labels:
        app.kubernetes.io/component: mimir
        app.kubernetes.io/instance: mimir-monolithic-mode
        app.kubernetes.io/name: mimir
        app.kubernetes.io/part-of: memberlist
    spec:
      containers:
      - args:
        - -target=all
        - -config.expand-env=true
        - -config.file=/etc/mimir/mimir.yaml
        - -memberlist.bind-addr=$(POD_IP)
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        envFrom:
        - secretRef:
            name: mimir-env-92ddctt858
        image: docker.io/grafana/mimir:2.11.0
        imagePullPolicy: IfNotPresent
        name: mimir
        ports:
        - containerPort: 8080
          name: http-metrics
        - containerPort: 9095
          name: grpc-distribut
        - containerPort: 7946
          name: http-memberlist
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
        resources:
          limits:
            cpu: 999m
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 55Mi
        volumeMounts:
        - mountPath: /etc/mimir
          name: config
        - mountPath: /data
          name: storage
      terminationGracePeriodSeconds: 60
      volumes:
      - configMap:
          name: mimir-config-958c4gm5k9
        name: config
      - emptyDir: {}
        name: storage
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: compactor
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-compactor
  namespace: logging-system
spec:
  podManagementPolicy: Parallel
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: compactor
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
  serviceName: loki-distributed-compactor-headless
  template:
    metadata:
      annotations:
        checksum/config: 684b1417c17a8d288d9276d1cc63260075683c560c3f2eb7eb8e881ae03ba479
      labels:
        app.kubernetes.io/component: compactor
        app.kubernetes.io/instance: loki-distributed
        app.kubernetes.io/name: loki-distributed
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: compactor
                  app.kubernetes.io/instance: loki-distributed
                  app.kubernetes.io/name: loki-distributed
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: compactor
                app.kubernetes.io/instance: loki-distributed
                app.kubernetes.io/name: loki-distributed
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=compactor
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-distributed-env-58m52b99kc
        image: docker.io/grafana/loki:2.9.6
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 300
        name: compactor
        ports:
        - containerPort: 3100
          name: http
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 1
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /tmp
          name: temp
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /var/loki-distributed-runtime
          name: runtime-config
        - mountPath: /var/loki
          name: data
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki-distributed
      terminationGracePeriodSeconds: 30
      volumes:
      - emptyDir: {}
        name: temp
      - configMap:
          name: loki-distributed
        name: config
      - configMap:
          name: loki-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: data
  updateStrategy:
    rollingUpdate:
      partition: 0
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: index-gateway
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-index-gateway
  namespace: logging-system
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: index-gateway
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
  serviceName: loki-distributed-index-gateway-headless
  template:
    metadata:
      annotations:
        checksum/config: 684b1417c17a8d288d9276d1cc63260075683c560c3f2eb7eb8e881ae03ba479
      labels:
        app.kubernetes.io/component: index-gateway
        app.kubernetes.io/instance: loki-distributed
        app.kubernetes.io/name: loki-distributed
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: index-gateway
                  app.kubernetes.io/instance: loki-distributed
                  app.kubernetes.io/name: loki-distributed
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: index-gateway
                app.kubernetes.io/instance: loki-distributed
                app.kubernetes.io/name: loki-distributed
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=index-gateway
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-distributed-env-58m52b99kc
        image: docker.io/grafana/loki:2.9.6
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 300
        name: index-gateway
        ports:
        - containerPort: 3100
          name: http
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 1
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /var/loki-distributed-runtime
          name: runtime-config
        - mountPath: /var/loki
          name: data
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki-distributed
      terminationGracePeriodSeconds: 300
      volumes:
      - configMap:
          name: loki-distributed
        name: config
      - configMap:
          name: loki-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: data
  updateStrategy:
    rollingUpdate:
      partition: 0
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: ingester
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/part-of: memberlist
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-ingester
  namespace: logging-system
spec:
  podManagementPolicy: Parallel
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: ingester
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
  serviceName: loki-distributed-ingester-headless
  template:
    metadata:
      annotations:
        checksum/config: 684b1417c17a8d288d9276d1cc63260075683c560c3f2eb7eb8e881ae03ba479
      labels:
        app.kubernetes.io/component: ingester
        app.kubernetes.io/instance: loki-distributed
        app.kubernetes.io/name: loki-distributed
        app.kubernetes.io/part-of: memberlist
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: ingester
                  app.kubernetes.io/instance: loki-distributed
                  app.kubernetes.io/name: loki-distributed
              topologyKey: failure-domain.beta.kubernetes.io/zone
            weight: 100
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: ingester
                app.kubernetes.io/instance: loki-distributed
                app.kubernetes.io/name: loki-distributed
            topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - -config.file=/etc/loki/config/config.yaml
        - -target=ingester
        - -config.expand-env=true
        envFrom:
        - secretRef:
            name: loki-distributed-env-58m52b99kc
        image: docker.io/grafana/loki:2.9.6
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 300
        name: ingester
        ports:
        - containerPort: 3100
          name: http
          protocol: TCP
        - containerPort: 9095
          name: grpc
          protocol: TCP
        - containerPort: 7946
          name: http-memberlist
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 30
          timeoutSeconds: 1
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/loki/config
          name: config
        - mountPath: /var/loki-distributed-runtime
          name: runtime-config
        - mountPath: /var/loki
          name: data
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      serviceAccountName: loki-distributed
      terminationGracePeriodSeconds: 300
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: ingester
            app.kubernetes.io/instance: loki-distributed
            app.kubernetes.io/name: loki-distributed
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
      - configMap:
          name: loki-distributed
        name: config
      - configMap:
          name: loki-distributed-runtime
        name: runtime-config
      - emptyDir: {}
        name: data
  updateStrategy:
    rollingUpdate:
      partition: 0
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: query-scheduler
    app.kubernetes.io/instance: loki-distributed
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: loki-distributed
    app.kubernetes.io/version: 2.9.4
    helm.sh/chart: loki-distributed-0.78.3
  name: loki-distributed-query-scheduler
  namespace: logging-system
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: query-scheduler
      app.kubernetes.io/instance: loki-distributed
      app.kubernetes.io/name: loki-distributed
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana-agent
    app.kubernetes.io/version: v0.40.3
    helm.sh/chart: grafana-agent-0.37.0
  name: grafana-agent
  namespace: monitoring-system
spec:
  minReadySeconds: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: grafana-agent
      app.kubernetes.io/name: grafana-agent
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: grafana-agent
        logs.agent.grafana.com/scrape: "true"
        logs.agent.grafana.com/scrub-level: debug
        profiles.grafana.com/cpu.port_name: http-metrics
        profiles.grafana.com/cpu.scrape: "false"
        profiles.grafana.com/goroutine.port_name: http-metrics
        profiles.grafana.com/goroutine.scrape: "false"
        profiles.grafana.com/memory.port_name: http-metrics
        profiles.grafana.com/memory.scrape: "false"
        pyroscope.io/service_name: grafana-agent
      labels:
        app.kubernetes.io/instance: grafana-agent
        app.kubernetes.io/name: grafana-agent
    spec:
      containers:
      - args:
        - run
        - /etc/agent/config.river
        - --storage.path=/tmp/agent
        - --server.http.listen-addr=0.0.0.0:80
        - --server.http.ui-path-prefix=/
        - --disable-reporting
        - --cluster.enabled=true
        - --cluster.join-addresses=grafana-agent-cluster
        env:
        - name: AGENT_MODE
          value: flow
        - name: AGENT_DEPLOY_MODE
          value: helm
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        envFrom:
        - secretRef:
            name: agent-env
            optional: true
        image: docker.io/grafana/agent:v0.40.3
        imagePullPolicy: IfNotPresent
        name: grafana-agent
        ports:
        - containerPort: 80
          name: http-metrics
        - containerPort: 4317
          name: grpc-otlp
          protocol: TCP
        - containerPort: 4318
          name: http-otlp
          protocol: TCP
        - containerPort: 9411
          name: zipkin
          protocol: TCP
        - containerPort: 6831
          name: jaeger-compact
          protocol: UDP
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 80
            scheme: HTTP
          initialDelaySeconds: 10
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /etc/agent
          name: config
        - mountPath: /var/log
          name: varlog
          readOnly: true
        - mountPath: /etc/agent-modules
          name: agent-modules
      - args:
        - --volume-dir=/etc/agent
        - --webhook-url=http://localhost:80/-/reload
        image: ghcr.io/jimmidyson/configmap-reload:v0.12.0
        name: config-reloader
        resources:
          requests:
            cpu: 1m
            memory: 5Mi
        volumeMounts:
        - mountPath: /etc/agent
          name: config
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: grafana-agent
      volumes:
      - configMap:
          name: agent-config-6thf5hghkg
        name: config
      - hostPath:
          path: /var/log
        name: varlog
      - configMap:
          name: agent-modules-cf8t5bf7t9
        name: agent-modules
  updateStrategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 2
    type: RollingUpdate
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana-agent
    app.kubernetes.io/version: v0.40.3
    helm.sh/chart: grafana-agent-0.37.0
  name: grafana-agent
  namespace: monitoring-system
spec:
  endpoints:
  - honorLabels: true
    port: http-metrics
    scheme: http
  selector:
    matchLabels:
      app.kubernetes.io/instance: grafana-agent
      app.kubernetes.io/name: grafana-agent
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: mimir
    app.kubernetes.io/instance: mimir-monolithic-mode
    app.kubernetes.io/managed-by: Kustomize
    app.kubernetes.io/name: mimir
    app.kubernetes.io/version: 2.11.0
  name: mimir
  namespace: monitoring-system
spec:
  endpoints:
  - port: http-metrics
    relabelings:
    - replacement: monitoring-system/mimir
      sourceLabels:
      - job
      targetLabel: job
    scheme: http
  namespaceSelector:
    matchNames:
    - monitoring-system
  selector:
    matchExpressions:
    - key: prometheus.io/service-monitor
      operator: NotIn
      values:
      - "false"
    matchLabels:
      app.kubernetes.io/component: mimir
      app.kubernetes.io/instance: mimir-monolithic-mode
      app.kubernetes.io/name: mimir
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  labels:
    app.kubernetes.io/instance: grafana-agent
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: grafana-agent
    app.kubernetes.io/version: v0.40.3
    helm.sh/chart: grafana-agent-0.37.0
  name: grafana-agent
  namespace: monitoring-system
spec:
  rules:
  - host: grafana-agent.localhost
    http:
      paths:
      - backend:
          service:
            name: grafana-agent
            port:
              number: 80
        path: /
        pathType: Prefix
  - host: agent.localhost
    http:
      paths:
      - backend:
          service:
            name: grafana-agent
            port:
              number: 80
        path: /
        pathType: Prefix
